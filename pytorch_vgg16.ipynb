{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7814d81",
   "metadata": {},
   "source": [
    "## Contents\n",
    "-  [1.Importing Libraries](#1)\n",
    "-  [2.Dataset Managament](#2)\n",
    "    -  [2.1.Downloading , Extracting and Spliting Dataset](#2.1)\n",
    "    -  [2.2.Pytorch Dataset](#2.2)\n",
    "    -  [2.3.Pytorch DataLoaders](#2.3)\n",
    "-  [3.Initializing pre-trained model](#3)\n",
    "-  [4.Training](#4)\n",
    "-  [5.Plotting Graphs](#5)\n",
    "    -  [5.1.Plotting Loss vs Epoch](#5.1)\n",
    "    -  [5.2.Plotting Accuracy vs Epoch](#5.2)\n",
    "-  [6.Loading and Testing](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b6cc1a",
   "metadata": {},
   "source": [
    "### 1.Importing Libraries <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e226cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset as Dataset\n",
    "from torch.utils.data import DataLoader as DataLoader\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import wget\n",
    "import tarfile\n",
    "import os\n",
    "import math\n",
    "import torchvision.transforms as T\n",
    "\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443ddc81",
   "metadata": {},
   "source": [
    "### 2.Dataset Managament <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002df12f",
   "metadata": {},
   "source": [
    "#### 1.Downloading , Extracting and Spliting Dataset <a class=\"anchor\" id=\"2.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b75f9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file_url = 'http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar'\n",
    "#check if the zipfile already exists\n",
    "\n",
    "if \"images.tar\" not in os.listdir() :\n",
    "    wget.download('http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar')\n",
    "    \n",
    "#check if the zip file is extracted\n",
    "\n",
    "if len(os.listdir(\"data/\"))== 0:\n",
    "\n",
    "    # open file\n",
    "    file = tarfile.open('images.tar')\n",
    "  \n",
    "    # extracting file\n",
    "    file.extractall('data/')\n",
    "    print(\"Extraction completed\")\n",
    "    file.close()\n",
    "     \n",
    "    # creating train , test and validation folders\n",
    "    path = \"data/\"\n",
    "    classes = os.listdir(path+'/images')\n",
    "    os.mkdir(\"data/train\")\n",
    "    os.mkdir(\"data/test\")\n",
    "    os.mkdir(\"data/validation\")\n",
    "            \n",
    "    for i in classes:\n",
    "        os.mkdir('data/train/'+i)\n",
    "        os.mkdir('data/test/'+i)\n",
    "        os.mkdir('data/validation/'+i)\n",
    "    \n",
    "    # (class_n , images_name) storing all the image name/location\n",
    "    images_path = []\n",
    "    for i in classes:\n",
    "        temp = []\n",
    "        for j in os.listdir(path+'images/'+i+'/'):\n",
    "            temp.append(j)\n",
    "        images_path.append(temp)\n",
    "    \n",
    "    # splitting train , test and validation images for each classes\n",
    "    \n",
    "    train = 0.9\n",
    "    test = 0.075\n",
    "    validatiation = 0.025\n",
    "\n",
    "    train_img_path = []\n",
    "    test_img_path = []\n",
    "    validation_img_path = []\n",
    "\n",
    "    for i in images_path:\n",
    "        n = len(i)\n",
    "        train_n = int(train*n)\n",
    "        test_n = int(test*n)\n",
    "        validation_n = n - train_n - test_n\n",
    "    \n",
    "        train_img_path.append(i[:train_n])\n",
    "        test_img_path.append(i[train_n:test_n+train_n])\n",
    "        validation_img_path.append(i[train_n+test_n:])\n",
    "    \n",
    "    # Moving corresponding images to the train , test and validation folders\n",
    "\n",
    "    for i,class_name in zip(train_img_path,classes):\n",
    "        for j in i:\n",
    "            os.rename(path+\"Images/\"+class_name+\"/\"+j, path+\"train/\"+class_name+\"/\"+j)\n",
    "        \n",
    "    for i,class_name in zip(test_img_path,classes):\n",
    "        for j in i:\n",
    "            os.rename(path+\"Images/\"+class_name+\"/\"+j, path+\"test/\"+class_name+\"/\"+j)\n",
    "        \n",
    "    for i,class_name in zip(validation_img_path,classes):\n",
    "        for j in i:\n",
    "            os.rename(path+\"Images/\"+class_name+\"/\"+j, path+\"validation/\"+class_name+\"/\"+j)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f734e2",
   "metadata": {},
   "source": [
    "#### 2.Pytorch Dataset <a class=\"anchor\" id=\"2.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf3ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests , io\n",
    "import os\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self , type = 'train' , transform = 'T.Resize((256,256))'):\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        self.transform = transform\n",
    "        self.n_classes = len(os.listdir('data/train/'))\n",
    "        if type == 'train':\n",
    "            path = 'data/train/'\n",
    "            classes = os.listdir(path)\n",
    "            for i in range(len(classes)):\n",
    "                for j in os.listdir(path+classes[i]):\n",
    "                    self.x.append(path+classes[i]+'/'+j)\n",
    "                    self.y.append(i)\n",
    "\n",
    "        if type == 'test':\n",
    "            path = 'data/test/'\n",
    "            classes = os.listdir(path)\n",
    "            for i in range(len(classes)):\n",
    "                for j in os.listdir(path+classes[i]):\n",
    "                    self.x.append(path+classes[i]+'/'+j)\n",
    "                    self.y.append(i)\n",
    "                    \n",
    "        if type == 'validation':\n",
    "            path = 'data/validation/'\n",
    "            classes = os.listdir(path)\n",
    "            for i in range(len(classes)):\n",
    "                for j in os.listdir(path+classes[i]):\n",
    "                    self.x.append(path+classes[i]+'/'+j)\n",
    "                    self.y.append(i)\n",
    "                    \n",
    "        self.len = len(self.x)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        image = self.transform(Image.fromarray(np.asarray(Image.open(self.x[i]))[:,:,:3]))\n",
    "        x = torch.FloatTensor(np.asarray(image))\n",
    "        return x,torch.LongTensor([self.y[i]])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d1ec80",
   "metadata": {},
   "source": [
    "#### 3.Pytorch DataLoaders <a class=\"anchor\" id=\"2.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdb4319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "classes = os.listdir('data/train/')\n",
    "n_classes = len(classes)\n",
    "\n",
    "transforms_train = T.Compose([\n",
    "        T.Resize((224,224)),\n",
    "        T.RandomRotation(degrees=30),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "transforms_test = T.Compose([\n",
    "        T.Resize((224,224)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "train_dataset = Dataset('train',transform =transforms_train )\n",
    "test_dataset = Dataset('test',transform =transforms_test )\n",
    "validation_dataset = Dataset('validation',transform =transforms_test )\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset , batch_size = batch_size , shuffle = True )\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d1541f",
   "metadata": {},
   "source": [
    "### 3.Initializing pre-trained model <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5986f6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=120, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False                     # Freezing the model parameters that isn't required to be trained\n",
    "num_features = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_features, n_classes)\n",
    "\n",
    "# for name,child in model.named_children():\n",
    "#     print(name,child)\n",
    "\n",
    "# class extended_model(nn.Module):\n",
    "#     def __init__(self,pretrained_model):\n",
    "#         super().__init__()\n",
    "#         self.pretrained_model = pretrained_model     #Pretrained models can be extended this way\n",
    "        \n",
    "#     def forward(self,x):\n",
    "#         x = self.pretrained_model(x)\n",
    "#         x = F.softmax(x)\n",
    "#         return x\n",
    "\n",
    "# model = extended_model(model)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baaa256",
   "metadata": {},
   "source": [
    "### 4.Training <a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2f115ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "epoch = 15\n",
    "train_dataset_size = train_dataset.__len__()\n",
    "validation_dataset_size = validation_dataset.__len__()\n",
    "train_n_minibatches = train_dataloader.__len__()\n",
    "validation_n_minibatches = validation_dataloader.__len__()\n",
    "\n",
    "device = 'cuda'\n",
    "model.to(device)\n",
    "loss_history = [[],[]] #[[train], [validation]]\n",
    "accuracy_history = [[],[]] #[[train], [validation]]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "029860ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS for EPOCH 1 BATCH 0/1155 TRAIN LOSS : 5.060275554656982 TRAIN ACCURACY : 0.0 VALIDATION LOSS : 4.820191442966461 VALIDATION ACCURACY : 3.75\n",
      "LOSS for EPOCH 1 BATCH 100/1155 TRAIN LOSS : 3.450173854827881 TRAIN ACCURACY : 25.0 VALIDATION LOSS : 2.2076663836836814 VALIDATION ACCURACY : 57.1875\n",
      "LOSS for EPOCH 1 BATCH 200/1155 TRAIN LOSS : 2.1874217987060547 TRAIN ACCURACY : 37.5 VALIDATION LOSS : 1.4452519714832306 VALIDATION ACCURACY : 66.71875\n",
      "LOSS for EPOCH 1 BATCH 300/1155 TRAIN LOSS : 2.367466449737549 TRAIN ACCURACY : 37.5 VALIDATION LOSS : 1.1492137908935547 VALIDATION ACCURACY : 70.46875\n",
      "LOSS for EPOCH 1 BATCH 400/1155 TRAIN LOSS : 1.1886022090911865 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.9750357158482075 VALIDATION ACCURACY : 72.03125\n",
      "LOSS for EPOCH 1 BATCH 500/1155 TRAIN LOSS : 1.6322888135910034 TRAIN ACCURACY : 56.25 VALIDATION LOSS : 0.892164409160614 VALIDATION ACCURACY : 75.625\n",
      "LOSS for EPOCH 1 BATCH 600/1155 TRAIN LOSS : 1.7459304332733154 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.8707784503698349 VALIDATION ACCURACY : 74.6875\n",
      "LOSS for EPOCH 1 BATCH 700/1155 TRAIN LOSS : 2.1282551288604736 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.8157217398285865 VALIDATION ACCURACY : 77.03125\n",
      "LOSS for EPOCH 1 BATCH 800/1155 TRAIN LOSS : 1.990744709968567 TRAIN ACCURACY : 43.75 VALIDATION LOSS : 0.8125188156962395 VALIDATION ACCURACY : 77.34375\n",
      "LOSS for EPOCH 1 BATCH 900/1155 TRAIN LOSS : 1.5178276300430298 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.8151942893862725 VALIDATION ACCURACY : 74.53125\n",
      "LOSS for EPOCH 1 BATCH 1000/1155 TRAIN LOSS : 1.04098379611969 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.7845219448208809 VALIDATION ACCURACY : 74.53125\n",
      "LOSS for EPOCH 1 BATCH 1100/1155 TRAIN LOSS : 1.6091960668563843 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.7616354610770941 VALIDATION ACCURACY : 76.09375\n",
      "---------------------------------------EPOCH 1-------------------------------------------\n",
      "Loss for EPOCH 1  TRAIN LOSS : 1.8260370680780122 TRAIN ACCURACY : 53.513708513708515\n",
      "VALIDATION LOSS for EPOCH 1 : 1.0481548156589269 VALIDATION ACCURACY : 72.38636363636364\n",
      "---------------------------------------------------------------------------------------------\n",
      "LOSS for EPOCH 2 BATCH 0/1155 TRAIN LOSS : 1.3264127969741821 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.7441968083381653 VALIDATION ACCURACY : 77.65625\n",
      "LOSS for EPOCH 2 BATCH 100/1155 TRAIN LOSS : 1.5328091382980347 TRAIN ACCURACY : 50.0 VALIDATION LOSS : 0.7367437377572059 VALIDATION ACCURACY : 76.71875\n",
      "LOSS for EPOCH 2 BATCH 200/1155 TRAIN LOSS : 1.503800392150879 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.7256783202290535 VALIDATION ACCURACY : 77.5\n",
      "LOSS for EPOCH 2 BATCH 300/1155 TRAIN LOSS : 1.6296730041503906 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.7496264640241861 VALIDATION ACCURACY : 77.1875\n",
      "LOSS for EPOCH 2 BATCH 400/1155 TRAIN LOSS : 1.1143696308135986 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.7364100527018309 VALIDATION ACCURACY : 76.875\n",
      "LOSS for EPOCH 2 BATCH 500/1155 TRAIN LOSS : 0.5924793481826782 TRAIN ACCURACY : 93.75 VALIDATION LOSS : 0.7181433465331792 VALIDATION ACCURACY : 77.96875\n",
      "LOSS for EPOCH 2 BATCH 600/1155 TRAIN LOSS : 1.9379574060440063 TRAIN ACCURACY : 43.75 VALIDATION LOSS : 0.7141028761863708 VALIDATION ACCURACY : 78.75\n",
      "LOSS for EPOCH 2 BATCH 700/1155 TRAIN LOSS : 0.8376930356025696 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.7478540256619454 VALIDATION ACCURACY : 76.875\n",
      "LOSS for EPOCH 2 BATCH 800/1155 TRAIN LOSS : 1.2172720432281494 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.7051335960626602 VALIDATION ACCURACY : 78.28125\n",
      "LOSS for EPOCH 2 BATCH 900/1155 TRAIN LOSS : 1.7038705348968506 TRAIN ACCURACY : 25.0 VALIDATION LOSS : 0.7085305402055383 VALIDATION ACCURACY : 78.59375\n",
      "LOSS for EPOCH 2 BATCH 1000/1155 TRAIN LOSS : 1.4198806285858154 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.7064624845981597 VALIDATION ACCURACY : 79.53125\n",
      "LOSS for EPOCH 2 BATCH 1100/1155 TRAIN LOSS : 1.0338516235351562 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.7180370267480611 VALIDATION ACCURACY : 77.1875\n",
      "---------------------------------------EPOCH 2-------------------------------------------\n",
      "Loss for EPOCH 2  TRAIN LOSS : 1.2810844867776483 TRAIN ACCURACY : 63.22150072150073\n",
      "VALIDATION LOSS for EPOCH 2 : 0.7242474973371084 VALIDATION ACCURACY : 77.76988636363636\n",
      "---------------------------------------------------------------------------------------------\n",
      "LOSS for EPOCH 3 BATCH 0/1155 TRAIN LOSS : 1.7074766159057617 TRAIN ACCURACY : 37.5 VALIDATION LOSS : 0.7269538410007954 VALIDATION ACCURACY : 78.125\n",
      "LOSS for EPOCH 3 BATCH 100/1155 TRAIN LOSS : 0.7374626398086548 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.702951468527317 VALIDATION ACCURACY : 78.90625\n",
      "LOSS for EPOCH 3 BATCH 200/1155 TRAIN LOSS : 0.965381920337677 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6824855916202068 VALIDATION ACCURACY : 78.75\n",
      "LOSS for EPOCH 3 BATCH 300/1155 TRAIN LOSS : 0.9398753643035889 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6848985146731138 VALIDATION ACCURACY : 77.8125\n",
      "LOSS for EPOCH 3 BATCH 400/1155 TRAIN LOSS : 1.3952447175979614 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6760435093194246 VALIDATION ACCURACY : 78.28125\n",
      "LOSS for EPOCH 3 BATCH 500/1155 TRAIN LOSS : 1.4949488639831543 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6791654393076897 VALIDATION ACCURACY : 77.8125\n",
      "LOSS for EPOCH 3 BATCH 600/1155 TRAIN LOSS : 1.1379780769348145 TRAIN ACCURACY : 50.0 VALIDATION LOSS : 0.7146039109677076 VALIDATION ACCURACY : 78.28125\n",
      "LOSS for EPOCH 3 BATCH 700/1155 TRAIN LOSS : 1.2753599882125854 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.7018616765737533 VALIDATION ACCURACY : 78.125\n",
      "LOSS for EPOCH 3 BATCH 800/1155 TRAIN LOSS : 1.2798147201538086 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6871340392157436 VALIDATION ACCURACY : 79.0625\n",
      "LOSS for EPOCH 3 BATCH 900/1155 TRAIN LOSS : 1.79429030418396 TRAIN ACCURACY : 37.5 VALIDATION LOSS : 0.6767608806490898 VALIDATION ACCURACY : 79.21875\n",
      "LOSS for EPOCH 3 BATCH 1000/1155 TRAIN LOSS : 1.0633797645568848 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6698561444878578 VALIDATION ACCURACY : 78.4375\n",
      "LOSS for EPOCH 3 BATCH 1100/1155 TRAIN LOSS : 1.2766286134719849 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6683835790492594 VALIDATION ACCURACY : 78.4375\n",
      "---------------------------------------EPOCH 3-------------------------------------------\n",
      "Loss for EPOCH 3  TRAIN LOSS : 1.183858708347077 TRAIN ACCURACY : 65.44733044733044\n",
      "VALIDATION LOSS for EPOCH 3 : 0.6858313413082876 VALIDATION ACCURACY : 78.4659090909091\n",
      "---------------------------------------------------------------------------------------------\n",
      "LOSS for EPOCH 4 BATCH 0/1155 TRAIN LOSS : 1.456262469291687 TRAIN ACCURACY : 50.0 VALIDATION LOSS : 0.6761092124506831 VALIDATION ACCURACY : 77.34375\n",
      "LOSS for EPOCH 4 BATCH 100/1155 TRAIN LOSS : 1.131605625152588 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6829731482081115 VALIDATION ACCURACY : 78.28125\n",
      "LOSS for EPOCH 4 BATCH 200/1155 TRAIN LOSS : 0.6084678769111633 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.6652294734492898 VALIDATION ACCURACY : 78.75\n",
      "LOSS for EPOCH 4 BATCH 300/1155 TRAIN LOSS : 0.8252885341644287 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6840651435777545 VALIDATION ACCURACY : 78.90625\n",
      "LOSS for EPOCH 4 BATCH 400/1155 TRAIN LOSS : 0.60111004114151 TRAIN ACCURACY : 93.75 VALIDATION LOSS : 0.6713022822514176 VALIDATION ACCURACY : 79.0625\n",
      "LOSS for EPOCH 4 BATCH 500/1155 TRAIN LOSS : 1.40985107421875 TRAIN ACCURACY : 50.0 VALIDATION LOSS : 0.6911244533956051 VALIDATION ACCURACY : 80.0\n",
      "LOSS for EPOCH 4 BATCH 600/1155 TRAIN LOSS : 1.3169803619384766 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6747881166636944 VALIDATION ACCURACY : 77.8125\n",
      "LOSS for EPOCH 4 BATCH 700/1155 TRAIN LOSS : 1.029914379119873 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6693947052583098 VALIDATION ACCURACY : 77.96875\n",
      "LOSS for EPOCH 4 BATCH 800/1155 TRAIN LOSS : 1.490350365638733 TRAIN ACCURACY : 56.25 VALIDATION LOSS : 0.6764066712930799 VALIDATION ACCURACY : 78.75\n",
      "LOSS for EPOCH 4 BATCH 900/1155 TRAIN LOSS : 0.7410758137702942 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.674120732024312 VALIDATION ACCURACY : 79.375\n",
      "LOSS for EPOCH 4 BATCH 1000/1155 TRAIN LOSS : 1.3232334852218628 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6797166464850306 VALIDATION ACCURACY : 79.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS for EPOCH 4 BATCH 1100/1155 TRAIN LOSS : 0.8676152229309082 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6705311117693782 VALIDATION ACCURACY : 79.375\n",
      "---------------------------------------EPOCH 4-------------------------------------------\n",
      "Loss for EPOCH 4  TRAIN LOSS : 1.1493128980522032 TRAIN ACCURACY : 66.13816738816739\n",
      "VALIDATION LOSS for EPOCH 4 : 0.6763320440341803 VALIDATION ACCURACY : 78.90625\n",
      "---------------------------------------------------------------------------------------------\n",
      "LOSS for EPOCH 5 BATCH 0/1155 TRAIN LOSS : 0.5741017460823059 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.686378822196275 VALIDATION ACCURACY : 78.59375\n",
      "LOSS for EPOCH 5 BATCH 100/1155 TRAIN LOSS : 0.8313283324241638 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.673441930860281 VALIDATION ACCURACY : 77.96875\n",
      "LOSS for EPOCH 5 BATCH 200/1155 TRAIN LOSS : 1.1172468662261963 TRAIN ACCURACY : 56.25 VALIDATION LOSS : 0.6924269597977399 VALIDATION ACCURACY : 77.96875\n",
      "LOSS for EPOCH 5 BATCH 300/1155 TRAIN LOSS : 0.7659047245979309 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6777020459994674 VALIDATION ACCURACY : 78.125\n",
      "LOSS for EPOCH 5 BATCH 400/1155 TRAIN LOSS : 1.3079535961151123 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.696663747727871 VALIDATION ACCURACY : 77.96875\n",
      "LOSS for EPOCH 5 BATCH 500/1155 TRAIN LOSS : 1.3047308921813965 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6787684019654989 VALIDATION ACCURACY : 79.53125\n",
      "LOSS for EPOCH 5 BATCH 600/1155 TRAIN LOSS : 0.4551268517971039 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.6904728185385466 VALIDATION ACCURACY : 78.59375\n",
      "LOSS for EPOCH 5 BATCH 700/1155 TRAIN LOSS : 0.9812136292457581 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6811299389228225 VALIDATION ACCURACY : 78.90625\n",
      "LOSS for EPOCH 5 BATCH 800/1155 TRAIN LOSS : 1.735541582107544 TRAIN ACCURACY : 56.25 VALIDATION LOSS : 0.6700178902596235 VALIDATION ACCURACY : 77.1875\n",
      "LOSS for EPOCH 5 BATCH 900/1155 TRAIN LOSS : 1.9065953493118286 TRAIN ACCURACY : 43.75 VALIDATION LOSS : 0.6486083721742034 VALIDATION ACCURACY : 79.21875\n",
      "LOSS for EPOCH 5 BATCH 1000/1155 TRAIN LOSS : 1.1370264291763306 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6915198629721999 VALIDATION ACCURACY : 78.28125\n",
      "LOSS for EPOCH 5 BATCH 1100/1155 TRAIN LOSS : 1.6575398445129395 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6646387934684753 VALIDATION ACCURACY : 78.125\n",
      "---------------------------------------EPOCH 5-------------------------------------------\n",
      "Loss for EPOCH 5  TRAIN LOSS : 1.099020608330702 TRAIN ACCURACY : 67.36111111111111\n",
      "VALIDATION LOSS for EPOCH 5 : 0.6786718875169754 VALIDATION ACCURACY : 78.35227272727273\n",
      "---------------------------------------------------------------------------------------------\n",
      "LOSS for EPOCH 6 BATCH 0/1155 TRAIN LOSS : 0.9858344793319702 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6555322570726275 VALIDATION ACCURACY : 77.96875\n",
      "LOSS for EPOCH 6 BATCH 100/1155 TRAIN LOSS : 1.0397894382476807 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6778207050636411 VALIDATION ACCURACY : 77.96875\n",
      "LOSS for EPOCH 6 BATCH 200/1155 TRAIN LOSS : 1.8175034523010254 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6726141065359116 VALIDATION ACCURACY : 78.75\n",
      "LOSS for EPOCH 6 BATCH 300/1155 TRAIN LOSS : 0.8626377582550049 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6528224417939782 VALIDATION ACCURACY : 79.375\n",
      "LOSS for EPOCH 6 BATCH 400/1155 TRAIN LOSS : 0.8827880620956421 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6719924997538328 VALIDATION ACCURACY : 80.0\n",
      "LOSS for EPOCH 6 BATCH 500/1155 TRAIN LOSS : 0.6574739217758179 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.6559100894257426 VALIDATION ACCURACY : 80.46875\n",
      "LOSS for EPOCH 6 BATCH 600/1155 TRAIN LOSS : 1.3272022008895874 TRAIN ACCURACY : 37.5 VALIDATION LOSS : 0.6643334957771003 VALIDATION ACCURACY : 79.21875\n",
      "LOSS for EPOCH 6 BATCH 700/1155 TRAIN LOSS : 0.8712419271469116 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6635321699082851 VALIDATION ACCURACY : 79.84375\n",
      "LOSS for EPOCH 6 BATCH 800/1155 TRAIN LOSS : 1.789724349975586 TRAIN ACCURACY : 43.75 VALIDATION LOSS : 0.6879431253299118 VALIDATION ACCURACY : 79.375\n",
      "LOSS for EPOCH 6 BATCH 900/1155 TRAIN LOSS : 1.1774194240570068 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6523084586486221 VALIDATION ACCURACY : 80.78125\n",
      "LOSS for EPOCH 6 BATCH 1000/1155 TRAIN LOSS : 0.965086042881012 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6515042634680868 VALIDATION ACCURACY : 80.15625\n",
      "LOSS for EPOCH 6 BATCH 1100/1155 TRAIN LOSS : 2.002823829650879 TRAIN ACCURACY : 56.25 VALIDATION LOSS : 0.6742769494652748 VALIDATION ACCURACY : 79.21875\n",
      "---------------------------------------EPOCH 6-------------------------------------------\n",
      "Loss for EPOCH 6  TRAIN LOSS : 1.0887976352657591 TRAIN ACCURACY : 67.89862914862914\n",
      "VALIDATION LOSS for EPOCH 6 : 0.6659143913791261 VALIDATION ACCURACY : 79.5596590909091\n",
      "---------------------------------------------------------------------------------------------\n",
      "LOSS for EPOCH 7 BATCH 0/1155 TRAIN LOSS : 0.9462459683418274 TRAIN ACCURACY : 56.25 VALIDATION LOSS : 0.6778057873249054 VALIDATION ACCURACY : 79.53125\n",
      "LOSS for EPOCH 7 BATCH 100/1155 TRAIN LOSS : 0.8386988639831543 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6553203856572509 VALIDATION ACCURACY : 80.0\n",
      "LOSS for EPOCH 7 BATCH 200/1155 TRAIN LOSS : 0.847662627696991 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.6529964061453939 VALIDATION ACCURACY : 79.375\n",
      "LOSS for EPOCH 7 BATCH 300/1155 TRAIN LOSS : 1.3794745206832886 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6634001376107335 VALIDATION ACCURACY : 78.90625\n",
      "LOSS for EPOCH 7 BATCH 400/1155 TRAIN LOSS : 1.2675395011901855 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6762134801596403 VALIDATION ACCURACY : 78.59375\n",
      "LOSS for EPOCH 7 BATCH 500/1155 TRAIN LOSS : 0.43247854709625244 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.6751710370182991 VALIDATION ACCURACY : 80.15625\n",
      "LOSS for EPOCH 7 BATCH 600/1155 TRAIN LOSS : 0.5873957872390747 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.6699115920811891 VALIDATION ACCURACY : 78.90625\n",
      "LOSS for EPOCH 7 BATCH 700/1155 TRAIN LOSS : 0.8927915096282959 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6622889315709471 VALIDATION ACCURACY : 79.6875\n",
      "LOSS for EPOCH 7 BATCH 800/1155 TRAIN LOSS : 1.4736777544021606 TRAIN ACCURACY : 56.25 VALIDATION LOSS : 0.6880963766947389 VALIDATION ACCURACY : 78.59375\n",
      "LOSS for EPOCH 7 BATCH 900/1155 TRAIN LOSS : 1.662341594696045 TRAIN ACCURACY : 56.25 VALIDATION LOSS : 0.6639451125636697 VALIDATION ACCURACY : 79.21875\n",
      "LOSS for EPOCH 7 BATCH 1000/1155 TRAIN LOSS : 1.5370534658432007 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6383683925494552 VALIDATION ACCURACY : 80.78125\n",
      "LOSS for EPOCH 7 BATCH 1100/1155 TRAIN LOSS : 1.0708578824996948 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6595564872026444 VALIDATION ACCURACY : 80.0\n",
      "---------------------------------------EPOCH 7-------------------------------------------\n",
      "Loss for EPOCH 7  TRAIN LOSS : 1.0714737318036875 TRAIN ACCURACY : 68.47763347763347\n",
      "VALIDATION LOSS for EPOCH 7 : 0.664115303568542 VALIDATION ACCURACY : 79.47443181818181\n",
      "---------------------------------------------------------------------------------------------\n",
      "LOSS for EPOCH 8 BATCH 0/1155 TRAIN LOSS : 0.8813114762306213 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6739984564483166 VALIDATION ACCURACY : 79.84375\n",
      "LOSS for EPOCH 8 BATCH 100/1155 TRAIN LOSS : 0.5085164904594421 TRAIN ACCURACY : 87.5 VALIDATION LOSS : 0.6557605192065239 VALIDATION ACCURACY : 79.84375\n",
      "LOSS for EPOCH 8 BATCH 200/1155 TRAIN LOSS : 0.9529944658279419 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6611204201355576 VALIDATION ACCURACY : 78.125\n",
      "LOSS for EPOCH 8 BATCH 300/1155 TRAIN LOSS : 0.6810243129730225 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.654001890681684 VALIDATION ACCURACY : 80.3125\n",
      "LOSS for EPOCH 8 BATCH 400/1155 TRAIN LOSS : 0.9044409990310669 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.647104406170547 VALIDATION ACCURACY : 80.625\n",
      "LOSS for EPOCH 8 BATCH 500/1155 TRAIN LOSS : 1.3370922803878784 TRAIN ACCURACY : 50.0 VALIDATION LOSS : 0.6541968323290348 VALIDATION ACCURACY : 80.15625\n",
      "LOSS for EPOCH 8 BATCH 600/1155 TRAIN LOSS : 0.6940552592277527 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6481861133128405 VALIDATION ACCURACY : 80.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS for EPOCH 8 BATCH 700/1155 TRAIN LOSS : 0.9184674620628357 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6791846344247461 VALIDATION ACCURACY : 80.46875\n",
      "LOSS for EPOCH 8 BATCH 800/1155 TRAIN LOSS : 0.8479284644126892 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6697673354297876 VALIDATION ACCURACY : 80.0\n",
      "LOSS for EPOCH 8 BATCH 900/1155 TRAIN LOSS : 1.0637633800506592 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6638426246121526 VALIDATION ACCURACY : 79.84375\n",
      "LOSS for EPOCH 8 BATCH 1000/1155 TRAIN LOSS : 0.993278980255127 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6691055627539754 VALIDATION ACCURACY : 80.78125\n",
      "LOSS for EPOCH 8 BATCH 1100/1155 TRAIN LOSS : 1.3808989524841309 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6731936905533076 VALIDATION ACCURACY : 79.0625\n",
      "---------------------------------------EPOCH 8-------------------------------------------\n",
      "Loss for EPOCH 8  TRAIN LOSS : 1.0572976101270486 TRAIN ACCURACY : 68.46320346320347\n",
      "VALIDATION LOSS for EPOCH 8 : 0.6614058208736506 VALIDATION ACCURACY : 79.98579545454545\n",
      "---------------------------------------------------------------------------------------------\n",
      "LOSS for EPOCH 9 BATCH 0/1155 TRAIN LOSS : 1.0864942073822021 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6772096663713455 VALIDATION ACCURACY : 79.6875\n",
      "LOSS for EPOCH 9 BATCH 100/1155 TRAIN LOSS : 0.6737843751907349 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.677193445712328 VALIDATION ACCURACY : 80.0\n",
      "LOSS for EPOCH 9 BATCH 200/1155 TRAIN LOSS : 0.952842116355896 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6599548721686006 VALIDATION ACCURACY : 79.84375\n",
      "LOSS for EPOCH 9 BATCH 300/1155 TRAIN LOSS : 0.7030300498008728 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.658552929200232 VALIDATION ACCURACY : 80.15625\n",
      "LOSS for EPOCH 9 BATCH 400/1155 TRAIN LOSS : 0.6779621243476868 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6490707108750939 VALIDATION ACCURACY : 79.84375\n",
      "LOSS for EPOCH 9 BATCH 500/1155 TRAIN LOSS : 1.1367563009262085 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6466319002211094 VALIDATION ACCURACY : 80.9375\n",
      "LOSS for EPOCH 9 BATCH 600/1155 TRAIN LOSS : 1.1050583124160767 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6568259589374066 VALIDATION ACCURACY : 80.3125\n",
      "LOSS for EPOCH 9 BATCH 700/1155 TRAIN LOSS : 1.1062204837799072 TRAIN ACCURACY : 56.25 VALIDATION LOSS : 0.6406152208335698 VALIDATION ACCURACY : 80.46875\n",
      "LOSS for EPOCH 9 BATCH 800/1155 TRAIN LOSS : 0.67523592710495 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6594247955828905 VALIDATION ACCURACY : 80.0\n",
      "LOSS for EPOCH 9 BATCH 900/1155 TRAIN LOSS : 1.0770245790481567 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6572122791782021 VALIDATION ACCURACY : 80.3125\n",
      "LOSS for EPOCH 9 BATCH 1000/1155 TRAIN LOSS : 0.7149516344070435 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6550693217664957 VALIDATION ACCURACY : 80.0\n",
      "LOSS for EPOCH 9 BATCH 1100/1155 TRAIN LOSS : 1.187827467918396 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6359475746750831 VALIDATION ACCURACY : 80.625\n",
      "---------------------------------------EPOCH 9-------------------------------------------\n",
      "Loss for EPOCH 9  TRAIN LOSS : 1.0530400080727291 TRAIN ACCURACY : 68.9411976911977\n",
      "VALIDATION LOSS for EPOCH 9 : 0.6542271826500919 VALIDATION ACCURACY : 80.22727272727273\n",
      "---------------------------------------------------------------------------------------------\n",
      "LOSS for EPOCH 10 BATCH 0/1155 TRAIN LOSS : 0.4660907983779907 TRAIN ACCURACY : 93.75 VALIDATION LOSS : 0.6356331503018737 VALIDATION ACCURACY : 80.9375\n",
      "LOSS for EPOCH 10 BATCH 100/1155 TRAIN LOSS : 1.3754364252090454 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.641458956617862 VALIDATION ACCURACY : 81.5625\n",
      "LOSS for EPOCH 10 BATCH 200/1155 TRAIN LOSS : 1.1910254955291748 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.667999639455229 VALIDATION ACCURACY : 79.375\n",
      "LOSS for EPOCH 10 BATCH 300/1155 TRAIN LOSS : 0.9809337258338928 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6518304700031876 VALIDATION ACCURACY : 81.25\n",
      "LOSS for EPOCH 10 BATCH 400/1155 TRAIN LOSS : 0.7272177338600159 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6595375902950764 VALIDATION ACCURACY : 80.0\n",
      "LOSS for EPOCH 10 BATCH 500/1155 TRAIN LOSS : 0.5772051811218262 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.6588472308591008 VALIDATION ACCURACY : 81.71875\n",
      "LOSS for EPOCH 10 BATCH 600/1155 TRAIN LOSS : 1.9360191822052002 TRAIN ACCURACY : 56.25 VALIDATION LOSS : 0.6746942576020956 VALIDATION ACCURACY : 79.6875\n",
      "LOSS for EPOCH 10 BATCH 700/1155 TRAIN LOSS : 1.6702866554260254 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6510504249483346 VALIDATION ACCURACY : 80.78125\n",
      "LOSS for EPOCH 10 BATCH 800/1155 TRAIN LOSS : 0.9508481025695801 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6494011424481869 VALIDATION ACCURACY : 81.40625\n",
      "LOSS for EPOCH 10 BATCH 900/1155 TRAIN LOSS : 0.6694115996360779 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.6583545494824647 VALIDATION ACCURACY : 80.15625\n",
      "LOSS for EPOCH 10 BATCH 1000/1155 TRAIN LOSS : 0.6730348467826843 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.6476047180593014 VALIDATION ACCURACY : 80.15625\n",
      "LOSS for EPOCH 10 BATCH 1100/1155 TRAIN LOSS : 1.3591604232788086 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6494815935380757 VALIDATION ACCURACY : 81.09375\n",
      "---------------------------------------EPOCH 10-------------------------------------------\n",
      "Loss for EPOCH 10  TRAIN LOSS : 1.053251111868656 TRAIN ACCURACY : 68.96645021645021\n",
      "VALIDATION LOSS for EPOCH 10 : 0.6554782339371741 VALIDATION ACCURACY : 80.6534090909091\n",
      "---------------------------------------------------------------------------------------------\n",
      "LOSS for EPOCH 11 BATCH 0/1155 TRAIN LOSS : 1.1839438676834106 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6499799652025103 VALIDATION ACCURACY : 81.875\n",
      "LOSS for EPOCH 11 BATCH 100/1155 TRAIN LOSS : 0.48588189482688904 TRAIN ACCURACY : 87.5 VALIDATION LOSS : 0.6631419772282243 VALIDATION ACCURACY : 80.3125\n",
      "LOSS for EPOCH 11 BATCH 200/1155 TRAIN LOSS : 0.62827068567276 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.6651701554656029 VALIDATION ACCURACY : 79.53125\n",
      "LOSS for EPOCH 11 BATCH 300/1155 TRAIN LOSS : 0.6457538604736328 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6648693669587373 VALIDATION ACCURACY : 80.15625\n",
      "LOSS for EPOCH 11 BATCH 400/1155 TRAIN LOSS : 1.214319109916687 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6815395895391703 VALIDATION ACCURACY : 79.84375\n",
      "LOSS for EPOCH 11 BATCH 500/1155 TRAIN LOSS : 0.7733854055404663 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6685899268835783 VALIDATION ACCURACY : 79.21875\n",
      "LOSS for EPOCH 11 BATCH 600/1155 TRAIN LOSS : 0.7157837748527527 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6779335083439946 VALIDATION ACCURACY : 79.21875\n",
      "LOSS for EPOCH 11 BATCH 700/1155 TRAIN LOSS : 1.3420591354370117 TRAIN ACCURACY : 56.25 VALIDATION LOSS : 0.6739549916237593 VALIDATION ACCURACY : 79.21875\n",
      "LOSS for EPOCH 11 BATCH 800/1155 TRAIN LOSS : 1.0382351875305176 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6832941617816687 VALIDATION ACCURACY : 79.84375\n",
      "LOSS for EPOCH 11 BATCH 900/1155 TRAIN LOSS : 1.0387935638427734 TRAIN ACCURACY : 56.25 VALIDATION LOSS : 0.6616682261228561 VALIDATION ACCURACY : 80.46875\n",
      "LOSS for EPOCH 11 BATCH 1000/1155 TRAIN LOSS : 1.3413525819778442 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.672879695892334 VALIDATION ACCURACY : 79.375\n",
      "LOSS for EPOCH 11 BATCH 1100/1155 TRAIN LOSS : 1.204961895942688 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6417196786031127 VALIDATION ACCURACY : 79.53125\n",
      "---------------------------------------EPOCH 11-------------------------------------------\n",
      "Loss for EPOCH 11  TRAIN LOSS : 1.0073245788291418 TRAIN ACCURACY : 69.59054834054835\n",
      "VALIDATION LOSS for EPOCH 11 : 0.6686146616766399 VALIDATION ACCURACY : 79.70170454545455\n",
      "---------------------------------------------------------------------------------------------\n",
      "LOSS for EPOCH 12 BATCH 0/1155 TRAIN LOSS : 1.0504465103149414 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6590072218328714 VALIDATION ACCURACY : 79.53125\n",
      "LOSS for EPOCH 12 BATCH 100/1155 TRAIN LOSS : 1.2895870208740234 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6563202295452356 VALIDATION ACCURACY : 80.46875\n",
      "LOSS for EPOCH 12 BATCH 200/1155 TRAIN LOSS : 1.0672214031219482 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6509475227445364 VALIDATION ACCURACY : 80.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS for EPOCH 12 BATCH 300/1155 TRAIN LOSS : 1.1622177362442017 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6436922011896968 VALIDATION ACCURACY : 80.0\n",
      "LOSS for EPOCH 12 BATCH 400/1155 TRAIN LOSS : 0.4936518669128418 TRAIN ACCURACY : 87.5 VALIDATION LOSS : 0.668072747439146 VALIDATION ACCURACY : 80.9375\n",
      "LOSS for EPOCH 12 BATCH 500/1155 TRAIN LOSS : 0.7614887356758118 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6816417500376701 VALIDATION ACCURACY : 79.21875\n",
      "LOSS for EPOCH 12 BATCH 600/1155 TRAIN LOSS : 1.4578883647918701 TRAIN ACCURACY : 56.25 VALIDATION LOSS : 0.6554629299789667 VALIDATION ACCURACY : 79.21875\n",
      "LOSS for EPOCH 12 BATCH 700/1155 TRAIN LOSS : 0.9929551482200623 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6562586948275566 VALIDATION ACCURACY : 80.9375\n",
      "LOSS for EPOCH 12 BATCH 800/1155 TRAIN LOSS : 0.8855549097061157 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6586027335375547 VALIDATION ACCURACY : 79.6875\n",
      "LOSS for EPOCH 12 BATCH 900/1155 TRAIN LOSS : 0.264362096786499 TRAIN ACCURACY : 93.75 VALIDATION LOSS : 0.6284430455416441 VALIDATION ACCURACY : 80.78125\n",
      "LOSS for EPOCH 12 BATCH 1000/1155 TRAIN LOSS : 1.2023268938064575 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6507497789338231 VALIDATION ACCURACY : 80.625\n",
      "LOSS for EPOCH 12 BATCH 1100/1155 TRAIN LOSS : 0.4752592444419861 TRAIN ACCURACY : 87.5 VALIDATION LOSS : 0.6528187271207571 VALIDATION ACCURACY : 81.09375\n",
      "---------------------------------------EPOCH 12-------------------------------------------\n",
      "Loss for EPOCH 12  TRAIN LOSS : 1.0234618359636434 TRAIN ACCURACY : 69.41017316017316\n",
      "VALIDATION LOSS for EPOCH 12 : 0.6548191237178715 VALIDATION ACCURACY : 80.29829545454545\n",
      "---------------------------------------------------------------------------------------------\n",
      "LOSS for EPOCH 13 BATCH 0/1155 TRAIN LOSS : 0.5715754628181458 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.676388232409954 VALIDATION ACCURACY : 80.78125\n",
      "LOSS for EPOCH 13 BATCH 100/1155 TRAIN LOSS : 1.351662039756775 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6699515487998724 VALIDATION ACCURACY : 80.3125\n",
      "LOSS for EPOCH 13 BATCH 200/1155 TRAIN LOSS : 1.7624140977859497 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6634775141254068 VALIDATION ACCURACY : 80.3125\n",
      "LOSS for EPOCH 13 BATCH 300/1155 TRAIN LOSS : 0.8398256897926331 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.6620791710913181 VALIDATION ACCURACY : 80.0\n",
      "LOSS for EPOCH 13 BATCH 400/1155 TRAIN LOSS : 0.3887026309967041 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.6748396383598447 VALIDATION ACCURACY : 80.3125\n",
      "LOSS for EPOCH 13 BATCH 500/1155 TRAIN LOSS : 1.4062482118606567 TRAIN ACCURACY : 50.0 VALIDATION LOSS : 0.6770844794809818 VALIDATION ACCURACY : 79.21875\n",
      "LOSS for EPOCH 13 BATCH 600/1155 TRAIN LOSS : 0.7445615530014038 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6934932675212622 VALIDATION ACCURACY : 78.59375\n",
      "LOSS for EPOCH 13 BATCH 700/1155 TRAIN LOSS : 1.666271448135376 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6557586159557104 VALIDATION ACCURACY : 80.3125\n",
      "LOSS for EPOCH 13 BATCH 800/1155 TRAIN LOSS : 0.3854706287384033 TRAIN ACCURACY : 87.5 VALIDATION LOSS : 0.6756019519641996 VALIDATION ACCURACY : 80.15625\n",
      "LOSS for EPOCH 13 BATCH 900/1155 TRAIN LOSS : 1.019587516784668 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6782140573486686 VALIDATION ACCURACY : 79.6875\n",
      "LOSS for EPOCH 13 BATCH 1000/1155 TRAIN LOSS : 1.4714844226837158 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6821354867890477 VALIDATION ACCURACY : 78.90625\n",
      "LOSS for EPOCH 13 BATCH 1100/1155 TRAIN LOSS : 0.3955761194229126 TRAIN ACCURACY : 93.75 VALIDATION LOSS : 0.6562477506697177 VALIDATION ACCURACY : 80.3125\n",
      "---------------------------------------EPOCH 13-------------------------------------------\n",
      "Loss for EPOCH 13  TRAIN LOSS : 1.004959613820175 TRAIN ACCURACY : 69.95851370851372\n",
      "VALIDATION LOSS for EPOCH 13 : 0.6717166801914572 VALIDATION ACCURACY : 79.82954545454545\n",
      "---------------------------------------------------------------------------------------------\n",
      "LOSS for EPOCH 14 BATCH 0/1155 TRAIN LOSS : 0.959286093711853 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6523430569097399 VALIDATION ACCURACY : 81.09375\n",
      "LOSS for EPOCH 14 BATCH 100/1155 TRAIN LOSS : 0.7167298793792725 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.6821924222633242 VALIDATION ACCURACY : 79.84375\n",
      "LOSS for EPOCH 14 BATCH 200/1155 TRAIN LOSS : 0.9601595401763916 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6949264166876674 VALIDATION ACCURACY : 78.59375\n",
      "LOSS for EPOCH 14 BATCH 300/1155 TRAIN LOSS : 1.5488208532333374 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6518739519640804 VALIDATION ACCURACY : 80.3125\n",
      "LOSS for EPOCH 14 BATCH 400/1155 TRAIN LOSS : 1.0196051597595215 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6799241596832871 VALIDATION ACCURACY : 80.46875\n",
      "LOSS for EPOCH 14 BATCH 500/1155 TRAIN LOSS : 0.938435435295105 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6616143669933081 VALIDATION ACCURACY : 80.15625\n",
      "LOSS for EPOCH 14 BATCH 600/1155 TRAIN LOSS : 0.9784154295921326 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6638044190593064 VALIDATION ACCURACY : 80.46875\n",
      "LOSS for EPOCH 14 BATCH 700/1155 TRAIN LOSS : 0.7957648038864136 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.6749313851818443 VALIDATION ACCURACY : 80.46875\n",
      "LOSS for EPOCH 14 BATCH 800/1155 TRAIN LOSS : 1.2780697345733643 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6746676689013839 VALIDATION ACCURACY : 79.375\n",
      "LOSS for EPOCH 14 BATCH 900/1155 TRAIN LOSS : 1.2884732484817505 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6759526818990708 VALIDATION ACCURACY : 79.0625\n",
      "LOSS for EPOCH 14 BATCH 1000/1155 TRAIN LOSS : 1.4514950513839722 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6914455939084292 VALIDATION ACCURACY : 77.96875\n",
      "LOSS for EPOCH 14 BATCH 1100/1155 TRAIN LOSS : 0.31690314412117004 TRAIN ACCURACY : 87.5 VALIDATION LOSS : 0.6668402234092354 VALIDATION ACCURACY : 80.0\n",
      "---------------------------------------EPOCH 14-------------------------------------------\n",
      "Loss for EPOCH 14  TRAIN LOSS : 0.9987592550067158 TRAIN ACCURACY : 69.95670995670996\n",
      "VALIDATION LOSS for EPOCH 14 : 0.6743793899955397 VALIDATION ACCURACY : 79.70170454545455\n",
      "---------------------------------------------------------------------------------------------\n",
      "LOSS for EPOCH 15 BATCH 0/1155 TRAIN LOSS : 1.4835633039474487 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.669503771327436 VALIDATION ACCURACY : 79.21875\n",
      "LOSS for EPOCH 15 BATCH 100/1155 TRAIN LOSS : 0.82833331823349 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6908428212627769 VALIDATION ACCURACY : 80.625\n",
      "LOSS for EPOCH 15 BATCH 200/1155 TRAIN LOSS : 1.1554131507873535 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6530118302442134 VALIDATION ACCURACY : 81.25\n",
      "LOSS for EPOCH 15 BATCH 300/1155 TRAIN LOSS : 0.8618255853652954 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.6705730123445391 VALIDATION ACCURACY : 81.09375\n",
      "LOSS for EPOCH 15 BATCH 400/1155 TRAIN LOSS : 0.7508561611175537 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.6729481822811068 VALIDATION ACCURACY : 82.34375\n",
      "LOSS for EPOCH 15 BATCH 500/1155 TRAIN LOSS : 1.3061326742172241 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6685005318373441 VALIDATION ACCURACY : 80.625\n",
      "LOSS for EPOCH 15 BATCH 600/1155 TRAIN LOSS : 0.7635214328765869 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6784937500953674 VALIDATION ACCURACY : 80.78125\n",
      "LOSS for EPOCH 15 BATCH 700/1155 TRAIN LOSS : 1.4185287952423096 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.6618568703532219 VALIDATION ACCURACY : 80.78125\n",
      "LOSS for EPOCH 15 BATCH 800/1155 TRAIN LOSS : 1.1685607433319092 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6608064506202936 VALIDATION ACCURACY : 80.3125\n",
      "LOSS for EPOCH 15 BATCH 900/1155 TRAIN LOSS : 1.2255778312683105 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6691540622152388 VALIDATION ACCURACY : 80.9375\n",
      "LOSS for EPOCH 15 BATCH 1000/1155 TRAIN LOSS : 1.1675411462783813 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6515717389062047 VALIDATION ACCURACY : 80.625\n",
      "LOSS for EPOCH 15 BATCH 1100/1155 TRAIN LOSS : 0.7075580358505249 TRAIN ACCURACY : 87.5 VALIDATION LOSS : 0.6608411031775177 VALIDATION ACCURACY : 80.78125\n",
      "---------------------------------------EPOCH 15-------------------------------------------\n",
      "Loss for EPOCH 15  TRAIN LOSS : 0.9757279707497849 TRAIN ACCURACY : 71.04797979797979\n",
      "VALIDATION LOSS for EPOCH 15 : 0.667145486667075 VALIDATION ACCURACY : 80.92329545454545\n",
      "---------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for e in range(epoch):\n",
    "    for batch_idx , (x ,y) in enumerate(train_dataloader):\n",
    "        model.train() # Setting mode to train\n",
    "        optimizer.zero_grad()\n",
    "        x , y = x.to(device) , y.to(device)\n",
    "        y_pred = model(x).to(device)\n",
    "        \n",
    "        # Calculating Loss\n",
    "        loss = criterion(y_pred,y.reshape(x.shape[0]))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_history[0].append(float(loss.detach()))\n",
    "        \n",
    "        #Calaculating Accuracy\n",
    "        correct = 0\n",
    "        y_pred = y_pred.cpu().detach().numpy().tolist()\n",
    "        y = y.cpu().detach().numpy().tolist()\n",
    "        for i in range(x.shape[0]):\n",
    "            n = 0\n",
    "            n = y_pred[i].index(max(y_pred[i]))\n",
    "            if n == y[i][0]:\n",
    "                correct = correct + 1\n",
    "        accuracy_history[0].append((correct/x.shape[0])*100)\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            # Printing Log\n",
    "            print(f'LOSS for EPOCH {e+1} BATCH {batch_idx}/{train_n_minibatches} TRAIN LOSS : {loss_history[0][-1]}',end = ' ')\n",
    "            print(f'TRAIN ACCURACY : {accuracy_history[0][-1]}',end = ' ')\n",
    "            with torch.no_grad():\n",
    "                # Calculating loss and accuracy for validation\n",
    "                model.eval()\n",
    "                for _batch_idx_ , (x ,y) in enumerate(validation_dataloader):\n",
    "                    x , y = x.to(device) , y.to(device)\n",
    "                    y_pred = model(x).to(device)\n",
    "                    validation_loss = criterion(y_pred,y.reshape(x.shape[0]))\n",
    "                    loss_history[1].append(float(validation_loss.detach()))\n",
    "                    \n",
    "                    correct = 0\n",
    "                    y_pred = y_pred.cpu().detach().numpy().tolist()\n",
    "                    y = y.cpu().detach().numpy().tolist()      \n",
    "                    for i in range(x.shape[0]):\n",
    "                        n = 0\n",
    "                        n = y_pred[i].index(max(y_pred[i]))\n",
    "                        if n == y[i][0]:\n",
    "                            correct = correct + 1\n",
    "                    accuracy_history[1].append((correct/x.shape[0])*100)\n",
    "                        \n",
    "                    \n",
    "                print(f'VALIDATION LOSS : {sum(loss_history[1][-1:-validation_n_minibatches-1:-1])/validation_n_minibatches}',end = ' ')\n",
    "                print(f'VALIDATION ACCURACY : {sum(accuracy_history[1][-1:-validation_n_minibatches-1:-1])/validation_n_minibatches}')\n",
    "    \n",
    "    # Saving the model progress\n",
    "    torch.save(model.state_dict(),'saved_model/vgg16v1')\n",
    "    \n",
    "    #Log for e+1th epoch\n",
    "    print(f'---------------------------------------EPOCH {e+1}-------------------------------------------')\n",
    "    print(f'Loss for EPOCH {e+1}  TRAIN LOSS : {sum(loss_history[0][-1:-train_n_minibatches-1:-1])/train_n_minibatches}',end = ' ')\n",
    "    print(f'TRAIN ACCURACY : {sum(accuracy_history[0][-1:-train_n_minibatches-1:-1])/train_n_minibatches}')\n",
    "    n_validation_losses = int(train_n_minibatches/100)*validation_n_minibatches\n",
    "    print(f'VALIDATION LOSS for EPOCH {e+1} : {sum(loss_history[1][-1:-1*n_validation_losses-1:-1])/n_validation_losses}',end = ' ')\n",
    "    print(f'VALIDATION ACCURACY : {sum(accuracy_history[1][-1:-1*n_validation_losses-1:-1])/n_validation_losses}')\n",
    "    print('---------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f05b1b9",
   "metadata": {},
   "source": [
    "### 5.Plotting Graphs<a class=\"anchor\" id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1c4758",
   "metadata": {},
   "source": [
    "#### 1.Plotting Loss vs Epoch<a class=\"anchor\" id=\"5.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee1fb104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n",
      "c:\\python\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting Loss per epoch\n",
    "loss_per_epoch = [[],[]]\n",
    "for i in range(epoch):\n",
    "    temp = 0\n",
    "    for j in loss_history[0][i*train_n_minibatches:(i+1)*train_n_minibatches]:\n",
    "        temp = temp + j\n",
    "    loss_per_epoch[0].append(temp/train_n_minibatches)\n",
    "    temp = 0\n",
    "    for j in loss_history[1][i*n_validation_losses:(i+1)*n_validation_losses]:\n",
    "        temp = temp + j\n",
    "    loss_per_epoch[1].append(temp/n_validation_losses)    \n",
    "\n",
    "sns.lineplot(range(len(loss_per_epoch[0])),loss_per_epoch[0])\n",
    "sns.lineplot(range(len(loss_per_epoch[1])),loss_per_epoch[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f6bb7b",
   "metadata": {},
   "source": [
    "#### 2.Plotting Accuracy vs Epoch<a class=\"anchor\" id=\"5.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c5d076e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n",
      "c:\\python\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD3CAYAAADSftWOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAon0lEQVR4nO3de3hU9b3v8feaNTMJmUkyJCQhJOGScAeBgnLRQKWWolbbU6RFOMVW27q1qLXe6wW01qrneeruPt1PN7Q9+9hNt9putcd26657V60IYSO1isidGJBcCSGXmUkyl7V+549JAgi5kGRYs2a+r+fJM5n7xzH5ZPGbtb6jKaUUQgghbMVhdQAhhBDnT8pbCCFsSMpbCCFsSMpbCCFsSMpbCCFsyHkhnsQ0TQxj8Du16Lo2pPtfSHbKCvbKK1njx0557ZQVhpbX5dJ7ve6ClLdhKFpa2gd9f58vY0j3v5DslBXslVeyxo+d8topKwwtb15eZq/XybKJEELYkJS3EELYkJS3EELYkJS3EELYkJS3EELYkJS3EELYkJS3EELY0AXZz1sIYTGl0CJBtM4WHKHm2GlnC1qo67RgPFr+ElRattVJxQBJeQthJ0qhRQJdJdzSVcLNp0r49HL+1PWaGe3zoXMdLsIliwmXXk2odDkqfeQF+o8SgyHlLUQiMcI4ArXobdXo/moc/mPo/prYaVs1jvaGPktYOTMw032Y6SNRaT7MnMlE0nyo0y9L7zqfNrLrNIuRoSrCH7xEWuVrpB29B+9f7idSfBmhsqsJTbgSlTHqAr4IYiCkvIW4kKKd6IFaHP5q9LZjsdOuL0fbMRzBBjROzcFQmgPTMxojs4RI0UJMz2jM9JxYAZ9WymaaD5WeDXraoGKpURcT9EwneOnDOBt3k1b5Ku7KV8n8ywN4336QyJiFhMq+SLj0SkxPwXC9GmIItP4+Bi0SifDAAw9QU1ODw+Hg8ccfx+l08sADD6BpGpMmTWLDhg04HL2/9xmJGDLbJEHZKa8tsiqFI1BLdvgoHXWV6P5jOPw1XUVdg97ecObNNR3TOwYjqxgzswQjswgjswQzqxgjsxjTUwi6K+6xz/naKoXetI+0yldJq3wVZ/NhFBqRwvmEy64mVHYVpndMfIMphaP9OHpLJXrzx+gtlaSH6glHNdDdKN2N0tO6vk8DZxrK4Y6dd6adeV3X6anvuy9PQ+ld99Fd4HCDo/eBUOcrXrNN+i3vP//5z/zxj3/kH/7hH9i2bRsvvPACkUiEG2+8kQULFrB+/XoWL17MsmXLen0MKe/EZae8CZVVKbSOEzibDuA8uR/95AGcTQfQTx7EEQmcupnD1VXOsWI2M0u6iro4VtKeAnBY/w/ggby2+smDp4q8aT8AkdHzCJV9kVDp1ZhZxYMPEOlAb/kYZ0tlV1FXord8jN7y8Zmvp54GvrEYhoEWDaEZYTDDaNFOMMJn/KtlKJSmg+7q+kPgQjlcsXJ3uPq4PPYHAYer54+A0l24Ll5LS3rZoHL0Vd79/tRMmDABwzAwTZNAIIDT6eSDDz5g/vz5ACxZsoRt27b1Wd66ruHzZQwievf9HUO6/4Vkp6xgr7yWZe1oQTuxH+34Pmjch9a4L3a+vannJmpEDip/Omr2aoxRU9EKpmJkjQNvATh0NBJ7jXJAr61vDpTOQS17iEjTIRz7/4hz3x9wbfsh3m0/xCyci5r2Jcyp18LICWffX5nQVoPWdAit6TA0HUY7Gftea6s586ZZxajciaix8zFyJ8a+z50EWUXoTifKMM+uaaXAjIIRgmjXlxGG7mI3QhA9df7022nd541I13Xdp7HvY38kuk57ruu+fTta5NP3i4AZu78qmobvMxcN5X/POfX785SRkUFNTQ1XXXUVzc3NbNy4kZ07d6JpGgAejwe/39/nY8hI2MRlp7xxzxppx3nyYM9WtPPkAfSTB9CD9T03MV1ejNwpRMcvx8iZTDRnKtHcKagRo6Drd+KMrG2h+OUdRuf92upFMOMWmHELjtYjsTc6K1/F9eaj6G8+SmTUTMKly8GMojdXxraoW6tiW8hdTJcXY2QZxuj5GFPLMHxlREeWYWRPANeIs59TAa2dA8jqAEbEvjTA1fVlkXgtm/Rb3s8++yzl5eXcfffd1NXV8Y1vfINIJNJzfTAYJCsra1DBhBgQpXC0HUVrPYmrrR1UFM00QBmxLS1lxvbAUFEwTTQVha7rNfP0742u23SdVwYYYfTWo7HSbjt66in1NKI5k4kUl9ORMxkjZwrR3KmxNd7TSlqAmT2ejrnfpWPud3G0VZP2cazIPe/+JPaGa2YJ0ZFlhIvLMXxlGCNLMXxlmBn58loOQb/lnZWVhcsV+7OVnZ1NNBpl+vTp7NixgwULFrBlyxYWLlwY96AitWgdTbirt+Gqfgf3sXfQ/dUA+Ibp8ZWmx9aaNR0jq4RI/mw6p32NaFdRG1njhvVNq1RhZhXTMedmOubcjNbZjHJlDHoPGNG3ft+wDAaDPPjggzQ2NhKJRLjhhhuYOXMmjzzyCJFIhNLSUn70ox+h673/oMsblokrYfJGOnDVvYv72BZc1VtxndgDgOnOIlK0iHDJYkaUzCTQHkVpzlixajqqq4Bx6GcUMo7u6xzgcHbdxwFa12Vx3uJLmNd1gOyU105ZwcK9TYaDlHfisiyvaeBs/BD3sa24qt/BVfdXNDOMcriIFF5MpHgx4eJyovmzevbGsNNra6esYK+8dsoKFq55CzEslEJvrcJVvRX3sXdw1VTgCLUCEM2dTsesGwmXLCZSOB9c9tj7RQgrSXmLuNHaT+Cu3tq1br0VPRDbHczwFhEqvYpIyWLCRZfJoddCDIKUd6pQCqKdsaFG4QCOSCA2Za7FhcvfHttjQxmx2ykztieHMrsuP/P8mZepnuu0ruscgXrc1VtxNu0FwEzLJlJ0Ke3zbiNcXI6ZPV72MhBiiKS8E50RRgu14gj70cJ+tHBX6Yb9XaeBrssCOLpOtfCnru8qbE0Z53wK3zBHVg43kcJLCCx8gEhxOdG8i2TPDSGGmZT3hWKEe8Z0OjpjIzu7x3j2jOzsGePZfGrWciTY70MrzYFyeVFub9epB+XOxPQUoNxezJ7rYpcrtyd2O5cHb5aXQDAc21ND07r2xNBBc6A0xxnn0bSu23Vfdtp5hw7E7q+c6aC74/+aCpHCpLyHg1LoLZW4P/kLjuARstoazy7naO/vNiuH89SozjRfbBbGqOldk+J8sVN35pnF21PKmeBMH/QyhPJlELHRO/dCiBgp78GKtOOu3ob7k7dwH30L3X8MAJWRi5428twlfMY85ZE9lyuXV9aAhRDnRcp7oJRCbz7cU9au2h2x/ZKdGYSLL6N97q2Exy4la+wUW+2DKoSwJynvvoSDuGu24T76Fu5P3uo5RDs6chIdF32T8LilRMbMl8N/hRAXnJT36ZRCbz7UU9au2ndPbV2XLKZ97m2Ex14+tLnFQggxDKS8w0Hc1VtPrV13HUgSzZkSO+pv3OeIFF4ie08IIRJKapZ3tJMRu3+N++ibuOreRTMjmC4PkeJy2i++nfDYpZiZRVanFEKIXqVkeWe89494/vrT2Nb17G8RHrtUtq6FELaSkuXtrn6HyOh5tFz3itVRhBBiUHr/yPckpYUDOBs+IFx0mdVRhBBi0FKuvF1176Ipg0jRpVZHEUKIQUu98q7e1jU4aZ7VUYQQYtBSr7xrthMZPRec5/h0aiGEsImUKm+tswVn425ZMhFC2F5KlberdgcaikixvFkphLC31CrvmgqUM51IwRyrowghxJCkVHm7a7bFPuBWBkkJIWwuZcpb62jC2bSfsKx3CyGSQMqUt6tmOwCRokUWJxFCiKFLmfJ211RgurxE82dbHUUIIYYsZcrbVb0t9sEJjpQc5yKESDIpUd6OYD3OlkoiMs9ECJEkUqK8XdUVAESK5c1KIURy6HcN4eWXX+b3v/89AKFQiH379vHMM8/w9NNPU1hYCMDtt9/O/Pnz45t0CFw1FZhp2URzp1sdRQghhkW/5b1ixQpWrFgBwGOPPcZ1113HRx99xL333svy5cvjHnA4uGu2ExmzEBy61VGEEGJYDHjZZPfu3Rw+fJhVq1axZ88eXnrpJdasWcNTTz1FNBqNZ8YhcbRVo7cdlXkmQoikMuBdLzZt2sS6desAuOyyy/j85z9PcXExGzZs4IUXXuDrX/96r/fVdQ2fL2PQIXXdMej7a0f/CkDatCtIG0KGgRpKVivYKa9kjR875bVTVohf3gGVd1tbG1VVVSxcuBCA6667jqysLACuuOIKXn/99T7vbxiKlpb2QYf0+TIGff/MQ2/hGJFLi2scDCHDQA0lqxXslFeyxo+d8topKwwtb15eZq/XDWjZZOfOnSxaFDsyUSnFl770Jerr6wHYvn07M2bMGFSwuFMKV01F7JB4TbM6jRBCDJsBbXlXVVVRXFwMgKZp/OhHP+K2224jPT2dsrIyvva1r8U15GDprVXogTraZb1bCJFkBlTe3/72t884X15eTnl5eVwCDSdXTff+3XJwjhAiuST1QTqumu0YngKM7AlWRxFCiGGVvOWtFO7qitgugrLeLYRIMklb3nrzIRwdjTLPRAiRlJK2vF3V2wAIyzwTIUQSStrydtdUYGSWYGaNtTqKEEIMu+Qsb2XiqtkuH3kmhEhaSVne+ol9OEItMgJWCJG0krK83TWx9W4ZRiWESFZJWd6umgqivlJMb6HVUYQQIi6Sr7zNKK7aHbLVLYRIaklX3s7G3TjCfilvIURSS7ry7p5nEi5aZHESIYSIn6Qrb3d1BdGcKaiMPKujCCFE3CRXeRthXHXvyv7dQoikl1Tl7Wz4AC3aIft3CyGSXlKVt7umAoUW+6R4IYRIYklV3q6aCqKjZqDSR1odRQgh4ip5yjvaiav+PdlFUAiREpKmvF3176EZIfnIMyFESkie8q6pQGk6kTHzrY4ihBBxlzTl7a6pIJo/C+XOtDqKEELEXXKUdziIs+F9We8WQqSMpChvV/1ONDNKWNa7hRAJIhw1qag6SW1LR1we3xmXR73A3NXbUA4XkdGXWB1FCJHClFLsrvPz2t4G/utAI22dUb73uYl8/TNjhv25kqK8XTUVRAs+A64RVkcRQqSg6pYO/mPfcf5jbwPHWjpJczq4fGIuV00vYPmsMQT8ncP+nLYvby3UhrNxN+3z7rA6ihAihfg7o/z5YCOv7W3gg5o2AOaVZPPNBWP53KRReNNi9erU47M6bfvydtXuQFOmzDMRQsRd1DDZfqSZ1/Y2sKWyibChGJ8zgu+Wj+fKafkUZqVfsCz2L++aCpSeRqRgrtVRhBBJSCnFvoYAr+1t4D/3N9LcEcE3wsVXZhVy1fQCphd40TTtgufqt7xffvllfv/73wMQCoXYt28fmzdv5oknnkDXdcrLy7ntttviHrQ37uptREZfDM4L9xdPCJH86ts6u9axj1N1sh2XrrGkLJerphVw6YSRuOK0HDJQ/Zb3ihUrWLFiBQCPPfYY1113HRs2bOBnP/sZJSUl3Hzzzezdu5fp06fHPeynaZ3NOJv2Elxw3wV/biFE8gmGo7x58ASv7W3gvWOtKGBOURY/WDaJz08eRVa6y+qIPQa8bLJ7924OHz7M3XffzbPPPsvYsWMBKC8vp6KiwpLyPvWRZ7LeLUQyM0xFdUsHhxqDNHZGae8I93pbjd6XMPpa3ag8EeQvh5sIRU2Kfel859JxXDUtn2JfYu7FNuDy3rRpE+vWrSMQCOD1ensu93g8HDt2rM/76rqGz5cx6JC67jjn/R2NO1EuD97Ji0BPjL+IvWVNVHbKK1njJ5HyBkJRDtT72V/vZ199G/vr/RxsCNARMeL6vFnpTlZ8poivzBnDnBLfsK1jx+u1HVB5t7W1UVVVxcKFCwkEAgSDwZ7rgsEgWVlZfd7fMBQtLe2DDunzZZzz/iM/3kKk8BJa/REgMujHH069ZU1UdsorWePHirxKKWrbOjl0PMihxiAHGwMcagxS03pqn+jMNCeT8jx8aWYBk/O8TMr3MGfCKIKBXvabVqr35+snj+7QcHQVdmvr8B0VOZTXNi+v91lNAyrvnTt3smhR7NPYvV4vLpeLTz75hJKSErZu3WrJG5Za8DjO5oMEpq684M8thJ0ppTgeCLO33s+eej/76v2ElSJdd5CZ5sSbpneddn/peN3O0y7T8aY5yXDrPWXXn86IQeWJIAcbY0V9qKuog+HY1rQGlIwcwbQCL1+aOZpJeR4m5XkoyEw7awt4hFsn5OjteS/8Xh9WGVB5V1VVUVxc3HP+scce45577sEwDMrLy5k9e3bcAvbGXbsdQOZ3C9GPts4Ie+v97K0PsKfez956PyeCsTVj3aExcZSH3Mw0WoJhals7CYSi+ENRIkbf26oODTzuU2XuTXOeUf7pLp2alk4ONQY41tKB2fVwHrfOxFEerpqWz6R8L5PzPJSN8jDCpcf7pUgqAyrvb3/722ecnzNnDr/73e/iEmigXNXbMN1ZREfNtDSHEImkM2Jw4Pipkt5b7+dYy6klhrEjR3DJWB/TR2cyY3Qmk/I8pLv0c/7TPhQ1e4o8GIoSCBn4Q9GeywJhg0BnlED41HV1bbHyD4QMguEoo7PSmZzn4QtT85iU52VSnocx2ekD3mIXvbPtQTqumorYBw075K+1SE1RU/HxiWDP8sfeej+VJ4J0bzDne91MH53JtTNHM310JtMLMslMH/ivfJrTQZrTTa7HPah8SilLDl5JFbYsb4e/FmfrETov+qbVUYQ4i1KK5vYwTcEwSilMFbvMUAqlwFRg9nyvur4447Zmz3Vn3ra5PcLeBj976vzsPx4gFDWB2Bt700d7+cb8klhRj84kz5tm6esgxR1ftixv2b9bJALDVNS2dlJ1sp0jTe2x05PtVDW197wRFw9pTgdT8r18ZVYhM7qKusSXLmWZYmxZ3u6aCsz0kRi5U62OIlJAZ8Tgk+aOnmI+cjJW1J80d5zxpl6ux82EnBFcNS2fyWOyMSNRNE3DATg0DU2LnToc4OC081psK7X7+1O3jV2un3Zfb5rOhJyMuE2qE/Zhv/JWClf1NiJFi0CTH2AxfPyd0XNuRde2dvbsI6wBY7LTmZCbwaLxOUzIyWB8bgYTcjLOWE+2237ewn5sV96Otk/QAzW0z/2u1VFEnAVCUQ42BtjfEODA8QDBiEk0avYc4uzQYgdCn3Fe697Tt3uLNnad1r2FGzuDRmzLVimoa+uk6mQHTcFTh1y7dI1xIzOYVpDJ1dPzGZ+TwficDMaOHEG67NImEoDtyttdsw1APmw4yTS3h9l/PMCBrqI+cDxwxi5ueV43o7PTiUZNlIodLaeU6joFRexNvTO+P+s2XedP+x4gPzONReNHnrEVPSY7Hb3XA0GEsJ7tyttVXYGRkY8xcqLVUcQgKKVo8Id6Crp7q/p44NRWb1F2OlPyvVw7czRT8r1MyfeS63HLUoQQp7FXeSsV27+7aFHf48FEQjCVorqlk/0Nfg4cD3LguJ/9DQFaO6NAbNliXE4Gc0t8TM33MrXAy+Q873ntiyxEqrLVb4neUonefpx2WTJJOJ0Rg6qT7V1zK4IcaPBz8LTZFc6uw7AvnziKKQVepuZ7e47uE0KcP1uVt6s6tt4dlnkmlule9jjUM2AoyOETAT5pPjW7It3pYHK+l6unFzA138uUAi+luRmWf/KIEMnEVuXtrqnA8I7BzBpndZSU0B6OTYI7dCLI4cYghxsDHDoRJBA6dQBKUXY6k/I8fH5yHpPyPEzM81Ikb/YJEXf2KW9l4qrZTnj8FbLePcxMpWLT3050FXRjkMMnglSftrdH9yS45VPzu8Z1eikblYHHbZ8fISGSiW1+8/Sm/Tg6T8oh8cNAKcX7Na385/5GDje1c7DBT0ckNiPDoUGJbwRT871cM6OAiaNia9OFWWfPVRZCWMc25e3ummci+3cPXiAU5bW9Dby0q46Pm9rxuHUuKsrmyxcVMmmUh4l5HkpzM+RNRCFswDbl7aquwMgah5lZZHUU29nf4OfFXXW8vu84nVGTaQVeHvnCZL4wNY/ReZmy77QQNmSP8jYNXLX/TWjiF61OYhudEYP/OtDIS7vq2FPvJ83p4Mqp+ayYXcj00b1/Lp4Qwh5sUd5a/Yc4wm1EimQXwf4cOdnOy7vq+Pc9DfhDUcbnjODupWV8cXqBHPwiRBKxxW+zdvQdgNiRleIsUcPk7comXtxVx18/aUF3aCydOIqVcwqZW5wtbzQKkYRsUt5biY6chOkpsDpKQqlv6+T3u+t5ZXc9TcEwozPT+G75eK6dOZpRg/zoKiGEPSR+eRsRtE+2E5my0uokCcFUiu1Hmnl5Vx1bP25CKbh0Qg7XzS7k0gk5cnCMECki4cvb2fghWiRIuDi1dxFsbg/zh48aePnDOmpbO8nJcHHDJSV8ZVYhY7LTrY4nhLjAEr683V3zTCJjUmu92zAVhxuD7Kpt5b1jrbzzcRMRQzG3OJt15eNZOmmUzAoRIoUlfHm7aipQ+TNQI3KsjhJX7WGD3XVtfFjTxq7aVj6q8/dM5Mvzulkxq5AVswspzfVYnFQIkQgSu7yNEK66nZjzbrQ6ybBr8IfYVdPKh7Vt7Kpp41BjAEPFPqZrYp6HK6flM7soi9ljsuXQdCHEWRK6vB2dzWhGCDVxudVRhsQwFR83Bfmgpq2nsOvaQkBsfOrMwky+sWAss8dkMWtMFt60hP7fIoRIAAndEqZnNCdu+pDswmKw0SHcHRGDj+piW9S7atvYXdvWswQyyuNmdlEW188tYk5RNpPzPDhl7VoIcZ4SurwB26x1m0rxu/dr+c+DjeytbetZAikdlcHyqV1LIEVZjMlKlyUQIcSQJXx520Fze5hH/3SAiqpmZhdnc8P8EmYXZTOrMEsOSRdCxMWAmmXTpk28+eabRCIRVq9ezYwZM/i7v/s7xo8fD8Dq1au5+uqr45kzYf2tuoWHX91PS0eE+66YyLc/W0Zra4fVsYQQSa7f8t6xYwfvv/8+zz//PB0dHfzzP/8zADfeeCM33XRT3AMmKlMpnt1xjE0VRyjKTuf/rv4MUwq8siQihLggNKWU6usGP/nJT9A0jUOHDhEIBLjvvvt48cUXqaqqwjAMxo0bx4MPPojX6+31MUzTxDD6fJo+6boDwzAHff/hdiIQ4p4XP2RbZRPXXFTI41+e0bOHSKJl7Y+d8krW+LFTXjtlhaHldfXxwSj9lvfDDz9MbW0tGzdupLq6mltvvZWbb76ZKVOmMHPmTP7pn/6JtrY27r///l4fIxIxhjTw3+fLSJgPDNj5STOPvHaAQCjK3UvL+B8XjT5jazuRsg6EnfJK1vixU147ZYWh5c3L6332fr/LJj6fj9LSUtxuN6WlpaSlpXH55ZeTm5sLwLJly3j88ccHFcxODFPxf/77KL/a/gnjckbwj9ddxMQ8OdpRCGGNfncwnjdvHu+88w5KKRoaGujo6ODmm2/mww8/BGD79u3MmDEj7kGt1BgIse7FD/nl9k+4eno+v/6fc6W4hRCW6nfLe+nSpezcuZOVK1eilGL9+vXk5OTw+OOP43K5GDVqVFJvef/3kZOsf+0AHRGD9csnc+3M0VZHEkKIge0qeN9995112QsvvDDsYRJJ1FT8ouIIz+44xoTcDDZeO0uGQgkhEoYcQXIODf4QD7+6jw9q2vjyRaO5Z2kZ6X286yuEEBealPenbPv4JBv+Yz8RQ/H41VO5clq+1ZGEEOIsUt5doobJz7ceYfNfq5mU5+HJa6YxLifD6lhCCHFOUt5AXVsnD/37PnbX+bludiHfv7yMNKdM+hNCJK6UL++3D5/gh68fxDAVP75mGsum5FkdSQgh+pWy5R0xTP73lipe+FsN0wq8/PiaaRT7RlgdSwghBiQly7sxEOLu/7eHfQ0BVn1mDHcsKcUtyyRCCBtJyfL+9bvHOHwiyP/60nSWThpldRwhhDhvKbe5qZTi7cNNLBw3UopbCGFbKVfeBxuD1PtDfHZirtVRhBBi0FKuvLccbkIDykulvIUQ9pVy5f12ZRMXjcki1+O2OooQQgxaSpV3fVsnB44HWFImW91CCHtLqfLeUnkSgM9KeQshbC7FyvsEY0eOYHyuzCwRQthbypR3IBTlvWOtstUthEgKKVPeFVUniZpK1ruFEEkhZcp7S2UTI0e4uGhMltVRhBBiyFKivKOGybaqk5SX5qA7NKvjCCHEkKVEeb9X3UogZMhRlUKIpJES5b3lcBNpTgcLxo20OooQQgyLpC9vpRRbKpuYP9YnHyIshEgaSV/eMohKCJGMkr68ZRCVECIZJX15yyAqIUQySury7h5EJUdVCiGSTVKXd/cgKjmqUgiRbJK8vGUQlRAiOQ3oA4g3bdrEm2++SSQSYfXq1cyfP58HHngATdOYNGkSGzZswOFIrL8D3YOoVs8tsjqKEEIMu34bd8eOHbz//vs8//zzbN68mfr6ep588knuvPNOnnvuOZRSvPHGGxci63npHkQluwgKIZJRv+W9detWJk+ezLp167jlllu4/PLL2bNnD/PnzwdgyZIlVFRUxD3o+eoeRDWzUAZRCSGST7/LJs3NzdTW1rJx40aqq6u59dZbUUqhabEBTx6PB7/f3+dj6LqGzzf4dWddd5zX/SOGScWRZr4wvYDcHM+gn3cwzjer1eyUV7LGj53y2ikrxC9vv+Xt8/koLS3F7XZTWlpKWloa9fX1PdcHg0GysvreujUMRUtL+6BD+nwZ53X/HUeb8XdGWVSSPaTnHYzzzWo1O+WVrPFjp7x2ygpDy5uXl9nrdf0um8ybN4933nkHpRQNDQ10dHSwaNEiduzYAcCWLVu4+OKLBxUsXmQQlRAi2fW75b106VJ27tzJypUrUUqxfv16iouLeeSRR3jmmWcoLS1l+fLlFyLrgCileLuyiQXjRsogKiFE0hrQroL33XffWZf95je/GfYww+FgY5AGf4ibF42zOooQQsRNYu2cPQy6B1FdVppjdRQhhIibpCtvGUQlhEgFSVXeMohKCJEqkqq8t1Q2AbBEjqoUQiS5pCvvcSNHMD7HPjvwCyHEYCRNeXcPopLxr0KIVJA05S2DqIQQqSRpyvvtwzKISgiROpKivCOGybaqkywuy0F3aFbHEUKIuEuK8v5bdSvBsMGSslFWRxFCiAsiKcr71CAqn9VRhBDigrB9ecsgKiFEKrJ9eR88HhtEJUdVCiFSie3Le0tlbBBVeZkMohJCpA7bl3f3IKqcDBlEJYRIHbYubxlEJYRIVbYubxlEJYRIVbYu77cPyyAqIURqsm15B0JR3qtulVkmQoiUZNvyrqg6iWEqmSIohEhJti1vGUQlhEhltixvGUQlhEh1tizvvx2TQVRCiNRmy/LeUimDqIQQqc125S2DqIQQwoblLYOohBDChuX9duUJGUQlhEh5tivvLZUnmSWDqIQQKc45kBt95Stfwev1AlBcXMznPvc5nn76aQoLCwG4/fbbmT9/fvxSdukeRHXHkglxfy4hhEhk/ZZ3KBRCKcXmzZt7Lvv7v/977r33XpYvXx7XcJ/WPYhqsax3CyFSXL/lvX//fjo6OrjpppuIRqPcdddd7Nmzh3379vHrX/+aWbNmcc899+B0DmgjfkhkEJUQQsRoSinV1w0OHDjArl27+OpXv8qRI0f4zne+w6pVq7jyyispLi5mw4YNTJ48ma9//eu9PoZpmhhGn0/TJ1130BwIseCpN7nx0vHct3zKoB8r3nTdgWGYVscYMDvllazxY6e8dsoKQ8vr6mN36H43lydMmMC4cePQNI0JEybg8/m45ppreta7r7jiCl5//fU+H8MwFC0t7ecZ+xSfL4M/7aohaioWFGcN6bHizefLSOh8n2anvJI1fuyU105ZYWh58/Iye72u371NXnzxRZ566ikAGhoa8Pv9fPWrX6W+vh6A7du3M2PGjEEFOx9vH24iJ0MGUQkhBAxgy3vlypX84Ac/YPXq1WiaxpNPPkl7ezu33XYb6enplJWV8bWvfS2uIcPR2CCqKyaPkkFUQgjBAMrb7Xbzk5/85KzLy8vL4xLoXN49clIGUQkhxGlscZDOG/uPyyAqIYQ4TcKXt1KKN/YfZ6EMohJCiB4JX94Hjwepa+2UT4gXQojTJHx5v115Ak2D8lIZRCWEEN0Sv7wPNzG3xCeDqIQQ4jQJXd4ngmEONga5YlqB1VGEECKhJHR5Z6U5ueGSEr46t8jqKEIIkVASurzdTge3L5mAT5ZMhBDiDAld3kIIIc5NylsIIWxIylsIIWxIylsIIWxIylsIIWxIylsIIWxIylsIIWxIylsIIWyo3w8gFkIIkXhky1sIIWxIylsIIWxIylsIIWxIylsIIWxIylsIIWxIylsIIWxIylsIIWwoYcvbNE3Wr1/PqlWrWLt2LUePHrU6Up8ikQj33nsva9asYeXKlbzxxhtWR+pXU1MTn/3sZ6msrLQ6Sr82bdrEqlWrWLFiBf/2b/9mdZxeRSIR7r77bq6//nrWrFmT0K/trl27WLt2LQBHjx5l9erVrFmzhg0bNmCapsXpznR61n379rFmzRrWrl3Lt771LU6cOGFxujOdnrXbH//4R1atWjWsz5Ow5f3nP/+ZcDjMb3/7W+6++26eeuopqyP16Q9/+AM+n4/nnnuOX/3qVzz++ONWR+pTJBJh/fr1pKenWx2lXzt27OD999/n+eefZ/PmzdTX11sdqVdvv/020WiUF154gXXr1vHTn/7U6kjn9Mtf/pKHH36YUCgEwJNPPsmdd97Jc889h1IqoTY+Pp31iSee4JFHHmHz5s0sW7aMX/7ylxYnPOXTWQH27t3Liy++yHAfD5mw5f3ee++xePFiAObMmcNHH31kcaK+XXnllXzve98DQCmFrusWJ+rb008/zfXXX09+fr7VUfq1detWJk+ezLp167jlllu4/PLLrY7UqwkTJmAYBqZpEggEcDqdVkc6p7Fjx/Kzn/2s5/yePXuYP38+AEuWLKGiosKqaGf5dNZnnnmGadOmAWAYBmlpaVZFO8unszY3N/PMM8/w4IMPDvtzJeZPFhAIBPB6vT3ndV0nGo0m7C+Dx+MBYrnvuOMO7rzzTmsD9eHll18mJyeHxYsX84tf/MLqOP1qbm6mtraWjRs3Ul1dza233sqf/vQnNE2zOtpZMjIyqKmp4aqrrqK5uZmNGzdaHemcli9fTnV1dc95pVTP6+nxePD7/VZFO8uns3ZvcPztb3/jN7/5Df/6r/9qVbSznJ7VMAweeughfvCDH8TlD0zCbnl7vV6CwWDPedM0E7a4u9XV1XHDDTfw5S9/mWuvvdbqOL166aWXqKioYO3atezbt4/777+fxsZGq2P1yufzUV5ejtvtprS0lLS0NE6ePGl1rHN69tlnKS8v5/XXX+eVV17hgQceOOOf0InK4ThVBcFgkKysLAvT9O+1115jw4YN/OIXvyAnJ8fqOOe0Z88ejh49yqOPPspdd93F4cOHeeKJJ4bt8RO2DefOnctbb73F1VdfzQcffMDkyZOtjtSnEydOcNNNN7F+/XoWLVpkdZw+nb6lsnbtWh599FHy8vIsTNS3efPm8S//8i/ceOONHD9+nI6ODnw+n9WxzikrKwuXywVAdnY20WgUwzAsTtW/6dOns2PHDhYsWMCWLVtYuHCh1ZF69corr/Db3/6WzZs3J+zPAcCsWbN49dVXAaiuruauu+7ioYceGrbHT9jyXrZsGdu2beP6669HKcWPf/xjqyP1aePGjbS1tfHzn/+cn//850DszQs7vCGY6JYuXcrOnTtZuXIlSinWr1+fsO8pfPOb3+TBBx9kzZo1RCIRvv/975ORkWF1rH7df//9PPLIIzzzzDOUlpayfPlyqyOdk2EYPPHEExQWFnL77bcDcMkll3DHHXdYnOzCk5GwQghhQwm75i2EEKJ3Ut5CCGFDUt5CCGFDUt5CCGFDUt5CCGFDUt5CCGFDUt5CCGFD/x82yopqE0QX8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting Accuracy per epoch\n",
    "accuracy_per_epoch = [[],[]]\n",
    "for i in range(epoch):\n",
    "    temp = 0\n",
    "    for j in accuracy_history[0][i*train_n_minibatches:(i+1)*train_n_minibatches]:\n",
    "        temp = temp + j\n",
    "    accuracy_per_epoch[0].append(temp/train_n_minibatches)\n",
    "    temp = 0\n",
    "    for j in accuracy_history[1][i*n_validation_losses:(i+1)*n_validation_losses]:\n",
    "        temp = temp + j\n",
    "    accuracy_per_epoch[1].append(temp/n_validation_losses)    \n",
    "\n",
    "sns.lineplot(range(len(accuracy_per_epoch[0])),accuracy_per_epoch[0])\n",
    "sns.lineplot(range(len(accuracy_per_epoch[1])),accuracy_per_epoch[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29684e1",
   "metadata": {},
   "source": [
    "### 6.Loading and Testing<a class=\"anchor\" id=\"6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "929fe8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=120, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the saved model\n",
    "model = models.vgg16(pretrained=True)\n",
    "num_features = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_features, n_classes)\n",
    "model.load_state_dict(torch.load('saved_model/vgg16v1', map_location='cpu'))\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6db7ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [16, 64, 224, 224]           1,792\n",
      "              ReLU-2         [16, 64, 224, 224]               0\n",
      "            Conv2d-3         [16, 64, 224, 224]          36,928\n",
      "              ReLU-4         [16, 64, 224, 224]               0\n",
      "         MaxPool2d-5         [16, 64, 112, 112]               0\n",
      "            Conv2d-6        [16, 128, 112, 112]          73,856\n",
      "              ReLU-7        [16, 128, 112, 112]               0\n",
      "            Conv2d-8        [16, 128, 112, 112]         147,584\n",
      "              ReLU-9        [16, 128, 112, 112]               0\n",
      "        MaxPool2d-10          [16, 128, 56, 56]               0\n",
      "           Conv2d-11          [16, 256, 56, 56]         295,168\n",
      "             ReLU-12          [16, 256, 56, 56]               0\n",
      "           Conv2d-13          [16, 256, 56, 56]         590,080\n",
      "             ReLU-14          [16, 256, 56, 56]               0\n",
      "           Conv2d-15          [16, 256, 56, 56]         590,080\n",
      "             ReLU-16          [16, 256, 56, 56]               0\n",
      "        MaxPool2d-17          [16, 256, 28, 28]               0\n",
      "           Conv2d-18          [16, 512, 28, 28]       1,180,160\n",
      "             ReLU-19          [16, 512, 28, 28]               0\n",
      "           Conv2d-20          [16, 512, 28, 28]       2,359,808\n",
      "             ReLU-21          [16, 512, 28, 28]               0\n",
      "           Conv2d-22          [16, 512, 28, 28]       2,359,808\n",
      "             ReLU-23          [16, 512, 28, 28]               0\n",
      "        MaxPool2d-24          [16, 512, 14, 14]               0\n",
      "           Conv2d-25          [16, 512, 14, 14]       2,359,808\n",
      "             ReLU-26          [16, 512, 14, 14]               0\n",
      "           Conv2d-27          [16, 512, 14, 14]       2,359,808\n",
      "             ReLU-28          [16, 512, 14, 14]               0\n",
      "           Conv2d-29          [16, 512, 14, 14]       2,359,808\n",
      "             ReLU-30          [16, 512, 14, 14]               0\n",
      "        MaxPool2d-31            [16, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-32            [16, 512, 7, 7]               0\n",
      "           Linear-33                 [16, 4096]     102,764,544\n",
      "             ReLU-34                 [16, 4096]               0\n",
      "          Dropout-35                 [16, 4096]               0\n",
      "           Linear-36                 [16, 4096]      16,781,312\n",
      "             ReLU-37                 [16, 4096]               0\n",
      "          Dropout-38                 [16, 4096]               0\n",
      "           Linear-39                  [16, 120]         491,640\n",
      "================================================================\n",
      "Total params: 134,752,184\n",
      "Trainable params: 134,752,184\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 9.19\n",
      "Forward/backward pass size (MB): 3500.39\n",
      "Params size (MB): 514.04\n",
      "Estimated Total Size (MB): 4023.62\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Displaying the model summary\n",
    "from torchsummary import summary\n",
    "summary(model, (3,224,224), batch_size=16, device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f3b9fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_history = []\n",
    "test_accuracy_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "050de6e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS : 0.6329619951385964  ACCURACY : 80.8736559139785\n"
     ]
    }
   ],
   "source": [
    "#Testing the model on test dataset\n",
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "for _batch_idx_ , (x ,y) in enumerate(test_dataloader):\n",
    "    y_pred = model(x)\n",
    "    test_loss = criterion(y_pred,y.reshape(x.shape[0]))\n",
    "    test_loss_history.append(float(test_loss.detach()))\n",
    "    correct = 0\n",
    "    y_pred = y_pred.detach().numpy().tolist()\n",
    "    y = y.detach().numpy().tolist()      \n",
    "    for i in range(x.shape[0]):\n",
    "        n = 0\n",
    "        n = y_pred[i].index(max(y_pred[i]))\n",
    "        if n == y[i][0]:\n",
    "            correct = correct + 1\n",
    "    test_accuracy_history.append((correct/len(y))*100)\n",
    "                        \n",
    "print(f'LOSS : {sum(test_loss_history)/len(test_loss_history)}  ACCURACY : {sum(test_accuracy_history)/len(test_accuracy_history)}')                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc4811f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

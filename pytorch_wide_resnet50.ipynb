{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b4df936",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- #### [1.Importing Libraries](#1)\n",
    "- #### [2.Dataset Managament](#2)\n",
    "    - #### [2.1.Downloading , Extracting and Spliting Dataset](#2.1)\n",
    "    - #### [2.2.Pytorch Dataset](#2.2)\n",
    "    - #### [2.3.Pytorch DataLoaders](#2.3)\n",
    "- #### [3.Initializing pre-trained model](#3)\n",
    "- #### [4.Training](#4)\n",
    "- #### [5.Plotting Graphs](#5)\n",
    "    - #### [5.1.Plotting Loss vs Epoch](#5.1)\n",
    "    - #### [5.2.Plotting Accuracy vs Epoch](#5.2)\n",
    "- #### [6.Loading and Testing](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36611fd4",
   "metadata": {},
   "source": [
    "### 1.Importing Libraries <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90b6defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset as Dataset\n",
    "from torch.utils.data import DataLoader as DataLoader\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import wget\n",
    "import tarfile\n",
    "import os\n",
    "import math\n",
    "import torchvision.transforms as T\n",
    "\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d095b6f9",
   "metadata": {},
   "source": [
    "### 2.Dataset Managament <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a23812",
   "metadata": {},
   "source": [
    "#### 1.Downloading , Extracting and Spliting Dataset <a class=\"anchor\" id=\"2.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b75f9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file_url = 'http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar'\n",
    "#check if the zipfile already exists\n",
    "\n",
    "if \"images.tar\" not in os.listdir() :\n",
    "    wget.download('http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar')\n",
    "    \n",
    "#check if the zip file is extracted\n",
    "\n",
    "if len(os.listdir(\"data/\"))== 0:\n",
    "\n",
    "    # open file\n",
    "    file = tarfile.open('images.tar')\n",
    "  \n",
    "    # extracting file\n",
    "    file.extractall('data/')\n",
    "    print(\"Extraction completed\")\n",
    "    file.close()\n",
    "     \n",
    "    # creating train , test and validation folders\n",
    "    path = \"data/\"\n",
    "    classes = os.listdir(path+'/images')\n",
    "    os.mkdir(\"data/train\")\n",
    "    os.mkdir(\"data/test\")\n",
    "    os.mkdir(\"data/validation\")\n",
    "            \n",
    "    for i in classes:\n",
    "        os.mkdir('data/train/'+i)\n",
    "        os.mkdir('data/test/'+i)\n",
    "        os.mkdir('data/validation/'+i)\n",
    "    \n",
    "    # (class_n , images_name) storing all the image name/location\n",
    "    images_path = []\n",
    "    for i in classes:\n",
    "        temp = []\n",
    "        for j in os.listdir(path+'images/'+i+'/'):\n",
    "            temp.append(j)\n",
    "        images_path.append(temp)\n",
    "    \n",
    "    # splitting train , test and validation images for each classes\n",
    "    \n",
    "    train = 0.9\n",
    "    test = 0.075\n",
    "    validatiation = 0.025\n",
    "\n",
    "    train_img_path = []\n",
    "    test_img_path = []\n",
    "    validation_img_path = []\n",
    "\n",
    "    for i in images_path:\n",
    "        n = len(i)\n",
    "        train_n = int(train*n)\n",
    "        test_n = int(test*n)\n",
    "        validation_n = n - train_n - test_n\n",
    "    \n",
    "        train_img_path.append(i[:train_n])\n",
    "        test_img_path.append(i[train_n:test_n+train_n])\n",
    "        validation_img_path.append(i[train_n+test_n:])\n",
    "    \n",
    "    # Moving corresponding images to the train , test and validation folders\n",
    "\n",
    "    for i,class_name in zip(train_img_path,classes):\n",
    "        for j in i:\n",
    "            os.rename(path+\"Images/\"+class_name+\"/\"+j, path+\"train/\"+class_name+\"/\"+j)\n",
    "        \n",
    "    for i,class_name in zip(test_img_path,classes):\n",
    "        for j in i:\n",
    "            os.rename(path+\"Images/\"+class_name+\"/\"+j, path+\"test/\"+class_name+\"/\"+j)\n",
    "        \n",
    "    for i,class_name in zip(validation_img_path,classes):\n",
    "        for j in i:\n",
    "            os.rename(path+\"Images/\"+class_name+\"/\"+j, path+\"validation/\"+class_name+\"/\"+j)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cbc3ed",
   "metadata": {},
   "source": [
    "#### 2.Pytorch Dataset <a class=\"anchor\" id=\"2.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf3ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self , type = 'train' , transform = 'T.Resize((256,256))'):\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        self.transform = transform\n",
    "        self.n_classes = len(os.listdir('data/train/'))\n",
    "        if type == 'train':\n",
    "            path = 'data/train/'\n",
    "            classes = os.listdir(path)\n",
    "            for i in range(len(classes)):\n",
    "                for j in os.listdir(path+classes[i]):\n",
    "                    self.x.append(path+classes[i]+'/'+j)\n",
    "                    self.y.append(i)\n",
    "\n",
    "        if type == 'test':\n",
    "            path = 'data/test/'\n",
    "            classes = os.listdir(path)\n",
    "            for i in range(len(classes)):\n",
    "                for j in os.listdir(path+classes[i]):\n",
    "                    self.x.append(path+classes[i]+'/'+j)\n",
    "                    self.y.append(i)\n",
    "                    \n",
    "        if type == 'validation':\n",
    "            path = 'data/validation/'\n",
    "            classes = os.listdir(path)\n",
    "            for i in range(len(classes)):\n",
    "                for j in os.listdir(path+classes[i]):\n",
    "                    self.x.append(path+classes[i]+'/'+j)\n",
    "                    self.y.append(i)\n",
    "                    \n",
    "        self.len = len(self.x)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self,i): # Returning ith image and corresponding label\n",
    "        image = self.transform(Image.fromarray(np.asarray(Image.open(self.x[i]))[:,:,:3]))\n",
    "        x = torch.FloatTensor(np.asarray(image))\n",
    "        return x,torch.LongTensor([self.y[i]])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a5077e",
   "metadata": {},
   "source": [
    "#### 3.Pytorch DataLoaders <a class=\"anchor\" id=\"2.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdb4319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "classes = os.listdir('data/train/')\n",
    "n_classes = len(classes)\n",
    "\n",
    "transforms_train = T.Compose([\n",
    "        T.Resize((224,224)),\n",
    "        T.RandomRotation(degrees=30), #Data Augmentation to prevent overfitting\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "transforms_test = T.Compose([\n",
    "        T.Resize((224,224)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "train_dataset = Dataset('train',transform =transforms_train )\n",
    "test_dataset = Dataset('test',transform =transforms_test )\n",
    "validation_dataset = Dataset('validation',transform =transforms_test )\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset , batch_size = batch_size , shuffle = True )\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0ab5f6",
   "metadata": {},
   "source": [
    "### 3.Initializing pre-trained model <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5986f6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Gokul adethya/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=120, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet50_2', pretrained=True) # Downloading the model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False                     # Freezing the model parameters that isn't required to be trained\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, n_classes)\n",
    "\n",
    "# for name,child in model.named_children():\n",
    "#     print(name,child)\n",
    "\n",
    "# class extended_model(nn.Module):\n",
    "#     def __init__(self,pretrained_model):\n",
    "#         super().__init__()\n",
    "#         self.pretrained_model = pretrained_model     #Pretrained models can be extended this way\n",
    "        \n",
    "#     def forward(self,x):\n",
    "#         x = self.pretrained_model(x)\n",
    "#         x = F.softmax(x)\n",
    "#         return x\n",
    "\n",
    "# model = extended_model(model)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d594a85",
   "metadata": {},
   "source": [
    "### 4.Training <a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2f115ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "epoch = 6\n",
    "train_dataset_size = train_dataset.__len__()\n",
    "validation_dataset_size = validation_dataset.__len__()\n",
    "train_n_minibatches = train_dataloader.__len__()\n",
    "validation_n_minibatches = validation_dataloader.__len__()\n",
    "\n",
    "device = 'cuda'\n",
    "model.to(device)\n",
    "loss_history = [[],[]] #[[train], [validation]]\n",
    "accuracy_history = [[],[]] #[[train], [validation]]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "029860ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS for EPOCH 1 BATCH 0/1155 TRAIN LOSS : 4.9413228034973145 TRAIN ACCURACY : 0.0 VALIDATION LOSS : 4.823765218257904 VALIDATION ACCURACY : 1.25\n",
      "LOSS for EPOCH 1 BATCH 100/1155 TRAIN LOSS : 4.544984340667725 TRAIN ACCURACY : 6.25 VALIDATION LOSS : 4.429252362251281 VALIDATION ACCURACY : 14.84375\n",
      "LOSS for EPOCH 1 BATCH 200/1155 TRAIN LOSS : 4.374787330627441 TRAIN ACCURACY : 6.25 VALIDATION LOSS : 4.072540128231049 VALIDATION ACCURACY : 26.875\n",
      "LOSS for EPOCH 1 BATCH 300/1155 TRAIN LOSS : 4.061705112457275 TRAIN ACCURACY : 12.5 VALIDATION LOSS : 3.731694746017456 VALIDATION ACCURACY : 36.5625\n",
      "LOSS for EPOCH 1 BATCH 400/1155 TRAIN LOSS : 3.850318670272827 TRAIN ACCURACY : 43.75 VALIDATION LOSS : 3.4004035234451293 VALIDATION ACCURACY : 52.03125\n",
      "LOSS for EPOCH 1 BATCH 500/1155 TRAIN LOSS : 3.2602427005767822 TRAIN ACCURACY : 56.25 VALIDATION LOSS : 3.1177640736103056 VALIDATION ACCURACY : 52.65625\n",
      "LOSS for EPOCH 1 BATCH 600/1155 TRAIN LOSS : 3.0547163486480713 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 2.882347524166107 VALIDATION ACCURACY : 60.78125\n",
      "LOSS for EPOCH 1 BATCH 700/1155 TRAIN LOSS : 3.4666190147399902 TRAIN ACCURACY : 31.25 VALIDATION LOSS : 2.638882064819336 VALIDATION ACCURACY : 59.0625\n",
      "LOSS for EPOCH 1 BATCH 800/1155 TRAIN LOSS : 2.958491086959839 TRAIN ACCURACY : 43.75 VALIDATION LOSS : 2.3825587391853333 VALIDATION ACCURACY : 65.78125\n",
      "LOSS for EPOCH 1 BATCH 900/1155 TRAIN LOSS : 3.0189874172210693 TRAIN ACCURACY : 56.25 VALIDATION LOSS : 2.1824941843748094 VALIDATION ACCURACY : 68.75\n",
      "LOSS for EPOCH 1 BATCH 1000/1155 TRAIN LOSS : 2.422528028488159 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 2.013225319981575 VALIDATION ACCURACY : 69.0625\n",
      "LOSS for EPOCH 1 BATCH 1100/1155 TRAIN LOSS : 2.021127462387085 TRAIN ACCURACY : 87.5 VALIDATION LOSS : 1.920810294151306 VALIDATION ACCURACY : 71.71875\n",
      "---------------------------------------EPOCH 1-------------------------------------------\n",
      "Loss for EPOCH 1  TRAIN LOSS : 3.4405827948541354 TRAIN ACCURACY : 40.62229437229437\n",
      "VALIDATION LOSS for EPOCH 1 : 2.9792702691121535 VALIDATION ACCURACY : 52.55681818181818\n",
      "---------------------------------------------------------------------------------------------\n",
      "LOSS for EPOCH 2 BATCH 0/1155 TRAIN LOSS : 2.799692153930664 TRAIN ACCURACY : 50.0 VALIDATION LOSS : 1.8235261112451553 VALIDATION ACCURACY : 74.6875\n",
      "LOSS for EPOCH 2 BATCH 100/1155 TRAIN LOSS : 1.7380036115646362 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 1.6907399833202361 VALIDATION ACCURACY : 75.0\n",
      "LOSS for EPOCH 2 BATCH 200/1155 TRAIN LOSS : 2.1869475841522217 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 1.6149744763970375 VALIDATION ACCURACY : 74.6875\n",
      "LOSS for EPOCH 2 BATCH 300/1155 TRAIN LOSS : 2.1514828205108643 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 1.5230350971221924 VALIDATION ACCURACY : 75.0\n",
      "LOSS for EPOCH 2 BATCH 400/1155 TRAIN LOSS : 2.1160571575164795 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 1.4951728120446206 VALIDATION ACCURACY : 76.5625\n",
      "LOSS for EPOCH 2 BATCH 500/1155 TRAIN LOSS : 1.9372767210006714 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 1.4125504896044732 VALIDATION ACCURACY : 76.875\n",
      "LOSS for EPOCH 2 BATCH 600/1155 TRAIN LOSS : 2.013922929763794 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 1.3091445863246918 VALIDATION ACCURACY : 75.78125\n",
      "LOSS for EPOCH 2 BATCH 700/1155 TRAIN LOSS : 1.762966513633728 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 1.266337801516056 VALIDATION ACCURACY : 77.65625\n",
      "LOSS for EPOCH 2 BATCH 800/1155 TRAIN LOSS : 1.481828212738037 TRAIN ACCURACY : 87.5 VALIDATION LOSS : 1.23554627597332 VALIDATION ACCURACY : 75.78125\n",
      "LOSS for EPOCH 2 BATCH 900/1155 TRAIN LOSS : 1.780918836593628 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 1.1826986111700535 VALIDATION ACCURACY : 78.28125\n",
      "LOSS for EPOCH 2 BATCH 1000/1155 TRAIN LOSS : 1.4911878108978271 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 1.1624458581209183 VALIDATION ACCURACY : 76.875\n",
      "LOSS for EPOCH 2 BATCH 1100/1155 TRAIN LOSS : 1.5595759153366089 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 1.152298466861248 VALIDATION ACCURACY : 78.125\n",
      "---------------------------------------EPOCH 2-------------------------------------------\n",
      "Loss for EPOCH 2  TRAIN LOSS : 1.954976183924324 TRAIN ACCURACY : 66.62878787878788\n",
      "VALIDATION LOSS for EPOCH 2 : 1.3677222234958952 VALIDATION ACCURACY : 76.42045454545455\n",
      "---------------------------------------------------------------------------------------------\n",
      "LOSS for EPOCH 3 BATCH 0/1155 TRAIN LOSS : 1.6395095586776733 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 1.0685738362371922 VALIDATION ACCURACY : 78.90625\n",
      "LOSS for EPOCH 3 BATCH 100/1155 TRAIN LOSS : 1.6989887952804565 TRAIN ACCURACY : 56.25 VALIDATION LOSS : 1.0638316988945007 VALIDATION ACCURACY : 78.59375\n",
      "LOSS for EPOCH 3 BATCH 200/1155 TRAIN LOSS : 1.2869154214859009 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 1.0651649951934814 VALIDATION ACCURACY : 76.875\n",
      "LOSS for EPOCH 3 BATCH 300/1155 TRAIN LOSS : 1.385475754737854 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.9937312506139279 VALIDATION ACCURACY : 78.90625\n",
      "LOSS for EPOCH 3 BATCH 400/1155 TRAIN LOSS : 1.501543641090393 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 1.0228702895343305 VALIDATION ACCURACY : 79.53125\n",
      "LOSS for EPOCH 3 BATCH 500/1155 TRAIN LOSS : 1.6266454458236694 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 1.0040051341056824 VALIDATION ACCURACY : 79.0625\n",
      "LOSS for EPOCH 3 BATCH 600/1155 TRAIN LOSS : 1.250407099723816 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.991183041036129 VALIDATION ACCURACY : 78.4375\n",
      "LOSS for EPOCH 3 BATCH 700/1155 TRAIN LOSS : 1.4137685298919678 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.9726993523538112 VALIDATION ACCURACY : 78.125\n",
      "LOSS for EPOCH 3 BATCH 800/1155 TRAIN LOSS : 1.3859889507293701 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.9622468672692776 VALIDATION ACCURACY : 78.75\n",
      "LOSS for EPOCH 3 BATCH 900/1155 TRAIN LOSS : 1.5046218633651733 TRAIN ACCURACY : 87.5 VALIDATION LOSS : 0.8913706578314304 VALIDATION ACCURACY : 80.78125\n",
      "LOSS for EPOCH 3 BATCH 1000/1155 TRAIN LOSS : 1.8102041482925415 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.8936998173594475 VALIDATION ACCURACY : 80.3125\n",
      "LOSS for EPOCH 3 BATCH 1100/1155 TRAIN LOSS : 1.53965163230896 TRAIN ACCURACY : 50.0 VALIDATION LOSS : 0.9239636771380901 VALIDATION ACCURACY : 80.15625\n",
      "---------------------------------------EPOCH 3-------------------------------------------\n",
      "Loss for EPOCH 3  TRAIN LOSS : 1.4723734258057235 TRAIN ACCURACY : 70.78823953823952\n",
      "VALIDATION LOSS for EPOCH 3 : 0.9804333437572826 VALIDATION ACCURACY : 79.04829545454545\n",
      "---------------------------------------------------------------------------------------------\n",
      "LOSS for EPOCH 4 BATCH 0/1155 TRAIN LOSS : 0.8607401251792908 TRAIN ACCURACY : 93.75 VALIDATION LOSS : 0.8637577705085278 VALIDATION ACCURACY : 79.6875\n",
      "LOSS for EPOCH 4 BATCH 100/1155 TRAIN LOSS : 1.6885981559753418 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.8661750964820385 VALIDATION ACCURACY : 80.3125\n",
      "LOSS for EPOCH 4 BATCH 200/1155 TRAIN LOSS : 1.7911561727523804 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.8526467613875865 VALIDATION ACCURACY : 78.75\n",
      "LOSS for EPOCH 4 BATCH 300/1155 TRAIN LOSS : 0.975152313709259 TRAIN ACCURACY : 87.5 VALIDATION LOSS : 0.8623531304299832 VALIDATION ACCURACY : 78.4375\n",
      "LOSS for EPOCH 4 BATCH 400/1155 TRAIN LOSS : 0.9186153411865234 TRAIN ACCURACY : 93.75 VALIDATION LOSS : 0.8416922867298127 VALIDATION ACCURACY : 79.53125\n",
      "LOSS for EPOCH 4 BATCH 500/1155 TRAIN LOSS : 1.425649642944336 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.8269061982631684 VALIDATION ACCURACY : 80.9375\n",
      "LOSS for EPOCH 4 BATCH 600/1155 TRAIN LOSS : 1.2786576747894287 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.8480738796293735 VALIDATION ACCURACY : 79.21875\n",
      "LOSS for EPOCH 4 BATCH 700/1155 TRAIN LOSS : 0.9878607988357544 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.8310900136828423 VALIDATION ACCURACY : 80.15625\n",
      "LOSS for EPOCH 4 BATCH 800/1155 TRAIN LOSS : 0.8973935842514038 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.8241175182163716 VALIDATION ACCURACY : 81.40625\n",
      "LOSS for EPOCH 4 BATCH 900/1155 TRAIN LOSS : 1.129441738128662 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.7858854476362467 VALIDATION ACCURACY : 80.9375\n",
      "LOSS for EPOCH 4 BATCH 1000/1155 TRAIN LOSS : 1.6725012063980103 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.835926266014576 VALIDATION ACCURACY : 79.53125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS for EPOCH 4 BATCH 1100/1155 TRAIN LOSS : 1.2348018884658813 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.777744361013174 VALIDATION ACCURACY : 80.46875\n",
      "---------------------------------------EPOCH 4-------------------------------------------\n",
      "Loss for EPOCH 4  TRAIN LOSS : 1.2578645976590903 TRAIN ACCURACY : 72.63708513708515\n",
      "VALIDATION LOSS for EPOCH 4 : 0.8320555417713794 VALIDATION ACCURACY : 79.9715909090909\n",
      "---------------------------------------------------------------------------------------------\n",
      "LOSS for EPOCH 5 BATCH 0/1155 TRAIN LOSS : 1.1308830976486206 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.7656354811042547 VALIDATION ACCURACY : 80.46875\n",
      "LOSS for EPOCH 5 BATCH 100/1155 TRAIN LOSS : 1.4353030920028687 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.7865335967391729 VALIDATION ACCURACY : 79.0625\n",
      "LOSS for EPOCH 5 BATCH 200/1155 TRAIN LOSS : 1.1915767192840576 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.7930111236870289 VALIDATION ACCURACY : 80.78125\n",
      "LOSS for EPOCH 5 BATCH 300/1155 TRAIN LOSS : 1.7527499198913574 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.7447354637086392 VALIDATION ACCURACY : 80.46875\n",
      "LOSS for EPOCH 5 BATCH 400/1155 TRAIN LOSS : 1.3015446662902832 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.787717928737402 VALIDATION ACCURACY : 80.46875\n",
      "LOSS for EPOCH 5 BATCH 500/1155 TRAIN LOSS : 1.111148476600647 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.7572017136961222 VALIDATION ACCURACY : 79.0625\n",
      "LOSS for EPOCH 5 BATCH 600/1155 TRAIN LOSS : 1.3652223348617554 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.7525837175548077 VALIDATION ACCURACY : 81.09375\n",
      "LOSS for EPOCH 5 BATCH 700/1155 TRAIN LOSS : 0.652908444404602 TRAIN ACCURACY : 87.5 VALIDATION LOSS : 0.7853099729865789 VALIDATION ACCURACY : 79.6875\n",
      "LOSS for EPOCH 5 BATCH 800/1155 TRAIN LOSS : 1.3876811265945435 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.7288200989365577 VALIDATION ACCURACY : 80.78125\n",
      "LOSS for EPOCH 5 BATCH 900/1155 TRAIN LOSS : 0.851370632648468 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.740961740911007 VALIDATION ACCURACY : 79.84375\n",
      "LOSS for EPOCH 5 BATCH 1000/1155 TRAIN LOSS : 1.2589349746704102 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.7279425647109747 VALIDATION ACCURACY : 80.78125\n",
      "LOSS for EPOCH 5 BATCH 1100/1155 TRAIN LOSS : 0.8127509355545044 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.7092406991869211 VALIDATION ACCURACY : 81.25\n",
      "---------------------------------------EPOCH 5-------------------------------------------\n",
      "Loss for EPOCH 5  TRAIN LOSS : 1.1398867825925092 TRAIN ACCURACY : 73.46320346320347\n",
      "VALIDATION LOSS for EPOCH 5 : 0.7558235109868374 VALIDATION ACCURACY : 80.29829545454545\n",
      "---------------------------------------------------------------------------------------------\n",
      "LOSS for EPOCH 6 BATCH 0/1155 TRAIN LOSS : 0.9066727757453918 TRAIN ACCURACY : 87.5 VALIDATION LOSS : 0.6975542280822993 VALIDATION ACCURACY : 82.1875\n",
      "LOSS for EPOCH 6 BATCH 100/1155 TRAIN LOSS : 1.136836051940918 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.7209504064172506 VALIDATION ACCURACY : 81.71875\n",
      "LOSS for EPOCH 6 BATCH 200/1155 TRAIN LOSS : 1.2622650861740112 TRAIN ACCURACY : 68.75 VALIDATION LOSS : 0.6773994103074074 VALIDATION ACCURACY : 81.25\n",
      "LOSS for EPOCH 6 BATCH 300/1155 TRAIN LOSS : 1.254542589187622 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.7402474526315928 VALIDATION ACCURACY : 80.46875\n",
      "LOSS for EPOCH 6 BATCH 400/1155 TRAIN LOSS : 0.7283273339271545 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.7370289497077465 VALIDATION ACCURACY : 81.5625\n",
      "LOSS for EPOCH 6 BATCH 500/1155 TRAIN LOSS : 1.0257896184921265 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.7111585762351751 VALIDATION ACCURACY : 80.15625\n",
      "LOSS for EPOCH 6 BATCH 600/1155 TRAIN LOSS : 1.1756362915039062 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.7521238911896944 VALIDATION ACCURACY : 79.6875\n",
      "LOSS for EPOCH 6 BATCH 700/1155 TRAIN LOSS : 1.0256154537200928 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.713390938192606 VALIDATION ACCURACY : 81.25\n",
      "LOSS for EPOCH 6 BATCH 800/1155 TRAIN LOSS : 0.6843554377555847 TRAIN ACCURACY : 81.25 VALIDATION LOSS : 0.7318261992186308 VALIDATION ACCURACY : 81.875\n",
      "LOSS for EPOCH 6 BATCH 900/1155 TRAIN LOSS : 1.0791525840759277 TRAIN ACCURACY : 87.5 VALIDATION LOSS : 0.7079506196081639 VALIDATION ACCURACY : 81.09375\n",
      "LOSS for EPOCH 6 BATCH 1000/1155 TRAIN LOSS : 1.0009922981262207 TRAIN ACCURACY : 62.5 VALIDATION LOSS : 0.7478820063173771 VALIDATION ACCURACY : 79.375\n",
      "LOSS for EPOCH 6 BATCH 1100/1155 TRAIN LOSS : 1.3783701658248901 TRAIN ACCURACY : 75.0 VALIDATION LOSS : 0.722040157020092 VALIDATION ACCURACY : 79.84375\n",
      "---------------------------------------EPOCH 6-------------------------------------------\n",
      "Loss for EPOCH 6  TRAIN LOSS : 1.0733953405252268 TRAIN ACCURACY : 74.43542568542567\n",
      "VALIDATION LOSS for EPOCH 6 : 0.7238180551677942 VALIDATION ACCURACY : 80.7528409090909\n",
      "---------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for e in range(epoch):\n",
    "    for batch_idx , (x ,y) in enumerate(train_dataloader):\n",
    "        model.train() # Setting mode to train\n",
    "        optimizer.zero_grad()\n",
    "        x , y = x.to(device) , y.to(device)\n",
    "        y_pred = model(x).to(device)\n",
    "        \n",
    "        # Calculating Loss\n",
    "        loss = criterion(y_pred,y.reshape(x.shape[0]))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_history[0].append(float(loss.detach()))\n",
    "        \n",
    "        #Calaculating Accuracy\n",
    "        correct = 0\n",
    "        y_pred = y_pred.cpu().detach().numpy().tolist()\n",
    "        y = y.cpu().detach().numpy().tolist()\n",
    "        for i in range(x.shape[0]):\n",
    "            n = 0\n",
    "            n = y_pred[i].index(max(y_pred[i]))\n",
    "            if n == y[i][0]:\n",
    "                correct = correct + 1\n",
    "        accuracy_history[0].append((correct/x.shape[0])*100)\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            # Printing Log\n",
    "            print(f'LOSS for EPOCH {e+1} BATCH {batch_idx}/{train_n_minibatches} TRAIN LOSS : {loss_history[0][-1]}',end = ' ')\n",
    "            print(f'TRAIN ACCURACY : {accuracy_history[0][-1]}',end = ' ')\n",
    "            with torch.no_grad():\n",
    "                # Calculating loss and accuracy for validation\n",
    "                model.eval()\n",
    "                for _batch_idx_ , (x ,y) in enumerate(validation_dataloader):\n",
    "                    x , y = x.to(device) , y.to(device)\n",
    "                    y_pred = model(x).to(device)\n",
    "                    validation_loss = criterion(y_pred,y.reshape(x.shape[0]))\n",
    "                    loss_history[1].append(float(validation_loss.detach()))\n",
    "                    \n",
    "                    correct = 0\n",
    "                    y_pred = y_pred.cpu().detach().numpy().tolist()\n",
    "                    y = y.cpu().detach().numpy().tolist()      \n",
    "                    for i in range(x.shape[0]):\n",
    "                        n = 0\n",
    "                        n = y_pred[i].index(max(y_pred[i]))\n",
    "                        if n == y[i][0]:\n",
    "                            correct = correct + 1\n",
    "                    accuracy_history[1].append((correct/x.shape[0])*100)\n",
    "                        \n",
    "                    \n",
    "                print(f'VALIDATION LOSS : {sum(loss_history[1][-1:-validation_n_minibatches-1:-1])/validation_n_minibatches}',end = ' ')\n",
    "                print(f'VALIDATION ACCURACY : {sum(accuracy_history[1][-1:-validation_n_minibatches-1:-1])/validation_n_minibatches}')\n",
    "    \n",
    "    # Saving the model progress\n",
    "    torch.save(model.state_dict(),'saved_model/wide_resnet50_v1')\n",
    "    \n",
    "    #Log for e+1th epoch\n",
    "    print(f'---------------------------------------EPOCH {e+1}-------------------------------------------')\n",
    "    print(f'Loss for EPOCH {e+1}  TRAIN LOSS : {sum(loss_history[0][-1:-train_n_minibatches-1:-1])/train_n_minibatches}',end = ' ')\n",
    "    print(f'TRAIN ACCURACY : {sum(accuracy_history[0][-1:-train_n_minibatches-1:-1])/train_n_minibatches}')\n",
    "    n_validation_losses = int(train_n_minibatches/100)*validation_n_minibatches\n",
    "    print(f'VALIDATION LOSS for EPOCH {e+1} : {sum(loss_history[1][-1:-1*n_validation_losses-1:-1])/n_validation_losses}',end = ' ')\n",
    "    print(f'VALIDATION ACCURACY : {sum(accuracy_history[1][-1:-1*n_validation_losses-1:-1])/n_validation_losses}')\n",
    "    print('---------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37d5a00",
   "metadata": {},
   "source": [
    "### 5.Plotting Graphs<a class=\"anchor\" id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bb935a",
   "metadata": {},
   "source": [
    "#### 1.Plotting Loss vs Epoch<a class=\"anchor\" id=\"5.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd4c814c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n",
      "c:\\python\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting Loss per epoch\n",
    "loss_per_epoch = [[],[]]\n",
    "for i in range(epoch):\n",
    "    temp = 0\n",
    "    for j in loss_history[0][i*train_n_minibatches:(i+1)*train_n_minibatches]:\n",
    "        temp = temp + j\n",
    "    loss_per_epoch[0].append(temp/train_n_minibatches)\n",
    "    temp = 0\n",
    "    for j in loss_history[1][i*n_validation_losses:(i+1)*n_validation_losses]:\n",
    "        temp = temp + j\n",
    "    loss_per_epoch[1].append(temp/n_validation_losses)    \n",
    "\n",
    "sns.lineplot(range(len(loss_per_epoch[0])),loss_per_epoch[0])\n",
    "sns.lineplot(range(len(loss_per_epoch[1])),loss_per_epoch[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45421038",
   "metadata": {},
   "source": [
    "#### 2.Plotting Accuracy vs Epoch<a class=\"anchor\" id=\"5.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41722263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n",
      "c:\\python\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting Accuracy per epoch\n",
    "accuracy_per_epoch = [[],[]]\n",
    "for i in range(epoch):\n",
    "    temp = 0\n",
    "    for j in accuracy_history[0][i*train_n_minibatches:(i+1)*train_n_minibatches]:\n",
    "        temp = temp + j\n",
    "    accuracy_per_epoch[0].append(temp/train_n_minibatches)\n",
    "    temp = 0\n",
    "    for j in accuracy_history[1][i*n_validation_losses:(i+1)*n_validation_losses]:\n",
    "        temp = temp + j\n",
    "    accuracy_per_epoch[1].append(temp/n_validation_losses)    \n",
    "\n",
    "sns.lineplot(range(len(accuracy_per_epoch[0])),accuracy_per_epoch[0])\n",
    "sns.lineplot(range(len(accuracy_per_epoch[1])),accuracy_per_epoch[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c602463",
   "metadata": {},
   "source": [
    "### 6.Loading and Testing<a class=\"anchor\" id=\"6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75326ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Gokul adethya/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=120, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the saved model\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet50_2', pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, n_classes)\n",
    "model.load_state_dict(torch.load('saved_model/wide_resnet50_v1', map_location='cpu'))\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fd6ab8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [16, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [16, 64, 112, 112]             128\n",
      "              ReLU-3         [16, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [16, 64, 56, 56]               0\n",
      "            Conv2d-5          [16, 128, 56, 56]           8,192\n",
      "       BatchNorm2d-6          [16, 128, 56, 56]             256\n",
      "              ReLU-7          [16, 128, 56, 56]               0\n",
      "            Conv2d-8          [16, 128, 56, 56]         147,456\n",
      "       BatchNorm2d-9          [16, 128, 56, 56]             256\n",
      "             ReLU-10          [16, 128, 56, 56]               0\n",
      "           Conv2d-11          [16, 256, 56, 56]          32,768\n",
      "      BatchNorm2d-12          [16, 256, 56, 56]             512\n",
      "           Conv2d-13          [16, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [16, 256, 56, 56]             512\n",
      "             ReLU-15          [16, 256, 56, 56]               0\n",
      "       Bottleneck-16          [16, 256, 56, 56]               0\n",
      "           Conv2d-17          [16, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-18          [16, 128, 56, 56]             256\n",
      "             ReLU-19          [16, 128, 56, 56]               0\n",
      "           Conv2d-20          [16, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-21          [16, 128, 56, 56]             256\n",
      "             ReLU-22          [16, 128, 56, 56]               0\n",
      "           Conv2d-23          [16, 256, 56, 56]          32,768\n",
      "      BatchNorm2d-24          [16, 256, 56, 56]             512\n",
      "             ReLU-25          [16, 256, 56, 56]               0\n",
      "       Bottleneck-26          [16, 256, 56, 56]               0\n",
      "           Conv2d-27          [16, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-28          [16, 128, 56, 56]             256\n",
      "             ReLU-29          [16, 128, 56, 56]               0\n",
      "           Conv2d-30          [16, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-31          [16, 128, 56, 56]             256\n",
      "             ReLU-32          [16, 128, 56, 56]               0\n",
      "           Conv2d-33          [16, 256, 56, 56]          32,768\n",
      "      BatchNorm2d-34          [16, 256, 56, 56]             512\n",
      "             ReLU-35          [16, 256, 56, 56]               0\n",
      "       Bottleneck-36          [16, 256, 56, 56]               0\n",
      "           Conv2d-37          [16, 256, 56, 56]          65,536\n",
      "      BatchNorm2d-38          [16, 256, 56, 56]             512\n",
      "             ReLU-39          [16, 256, 56, 56]               0\n",
      "           Conv2d-40          [16, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-41          [16, 256, 28, 28]             512\n",
      "             ReLU-42          [16, 256, 28, 28]               0\n",
      "           Conv2d-43          [16, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-44          [16, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [16, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [16, 512, 28, 28]           1,024\n",
      "             ReLU-47          [16, 512, 28, 28]               0\n",
      "       Bottleneck-48          [16, 512, 28, 28]               0\n",
      "           Conv2d-49          [16, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-50          [16, 256, 28, 28]             512\n",
      "             ReLU-51          [16, 256, 28, 28]               0\n",
      "           Conv2d-52          [16, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-53          [16, 256, 28, 28]             512\n",
      "             ReLU-54          [16, 256, 28, 28]               0\n",
      "           Conv2d-55          [16, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-56          [16, 512, 28, 28]           1,024\n",
      "             ReLU-57          [16, 512, 28, 28]               0\n",
      "       Bottleneck-58          [16, 512, 28, 28]               0\n",
      "           Conv2d-59          [16, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-60          [16, 256, 28, 28]             512\n",
      "             ReLU-61          [16, 256, 28, 28]               0\n",
      "           Conv2d-62          [16, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-63          [16, 256, 28, 28]             512\n",
      "             ReLU-64          [16, 256, 28, 28]               0\n",
      "           Conv2d-65          [16, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-66          [16, 512, 28, 28]           1,024\n",
      "             ReLU-67          [16, 512, 28, 28]               0\n",
      "       Bottleneck-68          [16, 512, 28, 28]               0\n",
      "           Conv2d-69          [16, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-70          [16, 256, 28, 28]             512\n",
      "             ReLU-71          [16, 256, 28, 28]               0\n",
      "           Conv2d-72          [16, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-73          [16, 256, 28, 28]             512\n",
      "             ReLU-74          [16, 256, 28, 28]               0\n",
      "           Conv2d-75          [16, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-76          [16, 512, 28, 28]           1,024\n",
      "             ReLU-77          [16, 512, 28, 28]               0\n",
      "       Bottleneck-78          [16, 512, 28, 28]               0\n",
      "           Conv2d-79          [16, 512, 28, 28]         262,144\n",
      "      BatchNorm2d-80          [16, 512, 28, 28]           1,024\n",
      "             ReLU-81          [16, 512, 28, 28]               0\n",
      "           Conv2d-82          [16, 512, 14, 14]       2,359,296\n",
      "      BatchNorm2d-83          [16, 512, 14, 14]           1,024\n",
      "             ReLU-84          [16, 512, 14, 14]               0\n",
      "           Conv2d-85         [16, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-86         [16, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [16, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [16, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [16, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [16, 1024, 14, 14]               0\n",
      "           Conv2d-91          [16, 512, 14, 14]         524,288\n",
      "      BatchNorm2d-92          [16, 512, 14, 14]           1,024\n",
      "             ReLU-93          [16, 512, 14, 14]               0\n",
      "           Conv2d-94          [16, 512, 14, 14]       2,359,296\n",
      "      BatchNorm2d-95          [16, 512, 14, 14]           1,024\n",
      "             ReLU-96          [16, 512, 14, 14]               0\n",
      "           Conv2d-97         [16, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-98         [16, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [16, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [16, 1024, 14, 14]               0\n",
      "          Conv2d-101          [16, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-102          [16, 512, 14, 14]           1,024\n",
      "            ReLU-103          [16, 512, 14, 14]               0\n",
      "          Conv2d-104          [16, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-105          [16, 512, 14, 14]           1,024\n",
      "            ReLU-106          [16, 512, 14, 14]               0\n",
      "          Conv2d-107         [16, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-108         [16, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [16, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [16, 1024, 14, 14]               0\n",
      "          Conv2d-111          [16, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-112          [16, 512, 14, 14]           1,024\n",
      "            ReLU-113          [16, 512, 14, 14]               0\n",
      "          Conv2d-114          [16, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-115          [16, 512, 14, 14]           1,024\n",
      "            ReLU-116          [16, 512, 14, 14]               0\n",
      "          Conv2d-117         [16, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-118         [16, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [16, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [16, 1024, 14, 14]               0\n",
      "          Conv2d-121          [16, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-122          [16, 512, 14, 14]           1,024\n",
      "            ReLU-123          [16, 512, 14, 14]               0\n",
      "          Conv2d-124          [16, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-125          [16, 512, 14, 14]           1,024\n",
      "            ReLU-126          [16, 512, 14, 14]               0\n",
      "          Conv2d-127         [16, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-128         [16, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [16, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [16, 1024, 14, 14]               0\n",
      "          Conv2d-131          [16, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-132          [16, 512, 14, 14]           1,024\n",
      "            ReLU-133          [16, 512, 14, 14]               0\n",
      "          Conv2d-134          [16, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-135          [16, 512, 14, 14]           1,024\n",
      "            ReLU-136          [16, 512, 14, 14]               0\n",
      "          Conv2d-137         [16, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-138         [16, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [16, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [16, 1024, 14, 14]               0\n",
      "          Conv2d-141         [16, 1024, 14, 14]       1,048,576\n",
      "     BatchNorm2d-142         [16, 1024, 14, 14]           2,048\n",
      "            ReLU-143         [16, 1024, 14, 14]               0\n",
      "          Conv2d-144           [16, 1024, 7, 7]       9,437,184\n",
      "     BatchNorm2d-145           [16, 1024, 7, 7]           2,048\n",
      "            ReLU-146           [16, 1024, 7, 7]               0\n",
      "          Conv2d-147           [16, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-148           [16, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [16, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [16, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [16, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [16, 2048, 7, 7]               0\n",
      "          Conv2d-153           [16, 1024, 7, 7]       2,097,152\n",
      "     BatchNorm2d-154           [16, 1024, 7, 7]           2,048\n",
      "            ReLU-155           [16, 1024, 7, 7]               0\n",
      "          Conv2d-156           [16, 1024, 7, 7]       9,437,184\n",
      "     BatchNorm2d-157           [16, 1024, 7, 7]           2,048\n",
      "            ReLU-158           [16, 1024, 7, 7]               0\n",
      "          Conv2d-159           [16, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-160           [16, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [16, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [16, 2048, 7, 7]               0\n",
      "          Conv2d-163           [16, 1024, 7, 7]       2,097,152\n",
      "     BatchNorm2d-164           [16, 1024, 7, 7]           2,048\n",
      "            ReLU-165           [16, 1024, 7, 7]               0\n",
      "          Conv2d-166           [16, 1024, 7, 7]       9,437,184\n",
      "     BatchNorm2d-167           [16, 1024, 7, 7]           2,048\n",
      "            ReLU-168           [16, 1024, 7, 7]               0\n",
      "          Conv2d-169           [16, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-170           [16, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [16, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [16, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [16, 2048, 1, 1]               0\n",
      "          Linear-174                  [16, 120]         245,880\n",
      "================================================================\n",
      "Total params: 67,080,120\n",
      "Trainable params: 67,080,120\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 9.19\n",
      "Forward/backward pass size (MB): 5788.39\n",
      "Params size (MB): 255.89\n",
      "Estimated Total Size (MB): 6053.47\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Displaying the model summary\n",
    "from torchsummary import summary\n",
    "summary(model, (3,224,224), batch_size=16 , device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffd640b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_history = []\n",
    "test_accuracy_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ddf1276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS : 0.6641809101546964  ACCURACY : 82.88978494623656\n"
     ]
    }
   ],
   "source": [
    "#Testing the model on test dataset\n",
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "for _batch_idx_ , (x ,y) in enumerate(test_dataloader):\n",
    "    y_pred = model(x)\n",
    "    test_loss = criterion(y_pred,y.reshape(x.shape[0]))\n",
    "    test_loss_history.append(float(test_loss.detach()))\n",
    "    correct = 0\n",
    "    y_pred = y_pred.detach().numpy().tolist()\n",
    "    y = y.detach().numpy().tolist()      \n",
    "    for i in range(x.shape[0]):\n",
    "        n = 0\n",
    "        n = y_pred[i].index(max(y_pred[i]))\n",
    "        if n == y[i][0]:\n",
    "            correct = correct + 1\n",
    "    test_accuracy_history.append((correct/len(y))*100)\n",
    "                        \n",
    "print(f'LOSS : {sum(test_loss_history)/len(test_loss_history)}  ACCURACY : {sum(test_accuracy_history)/len(test_accuracy_history)}')                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df267f38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
